#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
GSC CLI å‘½ä»¤å®šç¾© - å·²é‡æ§‹

- å°‡è¤‡é›œé‚è¼¯å§”è¨—çµ¦å¾Œç«¯æœå‹™å’Œä½œæ¥­ (jobs)ã€‚
- ä¿®å¾©äº†æ‰€æœ‰ä¸åŒ¹é…çš„æ–¹æ³•èª¿ç”¨ã€‚
- çµ±ä¸€äº†ä¾è³´æ³¨å…¥æ¨¡å¼ã€‚
"""
import typer
from typing import Optional, List, Dict, Any
from typing_extensions import Annotated
from datetime import datetime, timedelta
from rich.console import Console
from rich.table import Table
from rich.panel import Panel

from .dependencies import get_db_service, get_gsc_client, get_analysis_service
from ..services.database import Database, SyncMode
from ..services.gsc_client import GSCClient
from ..services.analysis_service import AnalysisService
from ..jobs.bulk_data_synchronizer import run_sync
from ..analysis.analytics_report_builder import build_report
from ..analysis.interactive_data_visualizer import InteractiveVisualizer

console = Console()
app = typer.Typer(help="GSC CLI - ä¼æ¥­ç´š Google Search Console æ•¸æ“šç®¡ç†å·¥å…·")
site_app = typer.Typer(help="ç®¡ç† GSC ç¶²ç«™å±¬æ€§")
sync_app = typer.Typer(name="sync", help="æ•¸æ“šåŒæ­¥ç›¸é—œå‘½ä»¤")
analyze_app = typer.Typer(name="analyze", help="æ•¸æ“šåˆ†æžç›¸é—œå‘½ä»¤")
auth_app = typer.Typer(name="auth", help="èªè­‰ç®¡ç†ç›¸é—œå‘½ä»¤")

# ç§»é™¤é€™å¹¾è¡Œï¼Œæˆ‘å€‘å°‡åœ¨ main.py ä¸­é€²è¡Œè¨»å†Š
# site_app.add_typer(sync_app)
# site_app.add_typer(analyze_app)

@auth_app.command("login")
def auth_login(ctx: typer.Context):
    """
    åŸ·è¡Œä¸€æ¬¡æ€§çš„ OAuth èªè­‰æµç¨‹ä»¥ç²å–æ†‘è­‰ã€‚
    """
    console.print("ðŸš€ [bold yellow]å•Ÿå‹• OAuth2 èªè­‰æµç¨‹...[/bold yellow]")
    gsc_client = ctx.obj.gsc_client()
    
    auth_url = gsc_client.get_auth_url()
    
    console.print("\n1. è«‹å°‡ä»¥ä¸‹ URL è¤‡è£½åˆ°æ‚¨çš„ç€è¦½å™¨ä¸­æ‰“é–‹ï¼Œä¸¦ç™»å…¥æ‚¨çš„ Google å¸³æˆ¶é€²è¡ŒæŽˆæ¬Šï¼š")
    console.print(f"\n[link={auth_url}]{auth_url}[/link]\n")
    
    console.print("2. æŽˆæ¬Šå¾Œï¼Œæ‚¨å°‡è¢«é‡å®šå‘åˆ°ä¸€å€‹ç„¡æ³•æ‰“é–‹çš„é é¢ (é€™æ˜¯æ­£å¸¸çš„)ã€‚è«‹å¾žè©²é é¢çš„ç€è¦½å™¨åœ°å€æ¬„ä¸­ï¼Œè¤‡è£½ `code=` å¾Œé¢çš„æ‰€æœ‰å…§å®¹ã€‚")
    
    auth_code = typer.prompt("3. è«‹åœ¨æ­¤è™•è²¼ä¸Šæ‚¨è¤‡è£½çš„æŽˆæ¬Šç¢¼ (code)")
    
    if not auth_code:
        console.print("[bold red]âŒ æœªæä¾›æŽˆæ¬Šç¢¼ï¼Œèªè­‰å·²å–æ¶ˆã€‚[/bold red]")
        raise typer.Exit(code=1)
        
    console.print("\nâ³ [cyan]æ­£åœ¨ä½¿ç”¨æŽˆæ¬Šç¢¼æ›å–æ†‘è­‰...[/cyan]")
    if gsc_client.handle_oauth_callback(auth_code.strip()):
        console.print("[bold green]âœ… èªè­‰æˆåŠŸï¼æ†‘è­‰å·²ä¿å­˜è‡³ token.jsonã€‚æ‚¨ç¾åœ¨å¯ä»¥é‹è¡Œéžäº’å‹•å¼è…³æœ¬äº†ã€‚[/bold green]")
    else:
        console.print("[bold red]âŒ èªè­‰å¤±æ•—ã€‚è«‹æª¢æŸ¥æ‚¨çš„æŽˆæ¬Šç¢¼æˆ–é…ç½®ã€‚[/bold red]")
        raise typer.Exit(code=1)

@site_app.command("list")
def list_sites(ctx: typer.Context):
    """åˆ—å‡ºæ‰€æœ‰æœ¬åœ°æ•¸æ“šåº«å’Œé ç¨‹ GSC å¸³æˆ¶ä¸­çš„ç«™é»žã€‚"""
    db = ctx.obj.db_service()
    gsc_client = ctx.obj.gsc_client()
    console.print("[bold cyan]--- é ç¨‹ GSC å¸³æˆ¶ç«™é»ž ---[/bold cyan]")
    try:
        gsc_sites = gsc_client.get_sites()
        if not gsc_sites:
            console.print("[yellow]åœ¨æ‚¨çš„ GSC å¸³æˆ¶ä¸­æ‰¾ä¸åˆ°ä»»ä½•ç«™é»žã€‚[/yellow]")
        else:
            remote_table = Table(title="GSC é ç¨‹ç«™é»ž")
            remote_table.add_column("ç«™é»ž URL", style="green")
            for site in gsc_sites:
                remote_table.add_row(site)
            console.print(remote_table)
    except Exception as e:
        console.print(f"[red]âŒ ç„¡æ³•å¾ž Google API ç²å–ç«™é»žåˆ—è¡¨: {e}[/red]")

    console.print("\n[bold cyan]--- æœ¬åœ°æ•¸æ“šåº«ç«™é»ž ---[/bold cyan]")
    db_sites = db.get_sites(active_only=False)
    if not db_sites:
        console.print("[yellow]æ•¸æ“šåº«ä¸­æ²’æœ‰ä»»ä½•ç«™é»žã€‚[/yellow]")
    else:
        local_table = Table(title="æœ¬åœ°æ•¸æ“šåº«ç«™é»ž")
        local_table.add_column("ID", style="cyan")
        local_table.add_column("åç¨±", style="magenta")
        local_table.add_column("ç¶²åŸŸ", style="green")
        local_table.add_column("ç‹€æ…‹", style="yellow")
        for site in db_sites:
            status = "æœ‰æ•ˆ" if site['is_active'] else "ç„¡æ•ˆ"
            local_table.add_row(str(site['id']), site['name'], site['domain'], status)
        console.print(local_table)

@site_app.command("add")
def add_site(ctx: typer.Context,
    site_url: Annotated[str, typer.Argument(help="è¦æ·»åŠ çš„ GSC ç¶²ç«™ URLã€‚")],
):
    """æ‰‹å‹•æ·»åŠ ä¸€å€‹ GSC ç«™é»žåˆ°æ•¸æ“šåº«ã€‚"""
    db = ctx.obj.db_service()
    site_name = site_url.replace("sc-domain:", "").replace("https://", "").replace("http://", "").rstrip('/')
    try:
        site_id = db.add_site(domain=site_url, name=site_name)
        console.print(f"[green]âœ… ç«™é»ž '{site_name}' æ·»åŠ æˆåŠŸï¼ŒID: {site_id}[/green]")
    except Exception as e:
        console.print(f"[red]âŒ æ·»åŠ ç«™é»žå¤±æ•—: {e}[/red]")

@site_app.command("cleanup-duplicates", help="æ¸…ç†å›  bug ç”¢ç”Ÿçš„é‡è¤‡ç«™é»žåç¨±ã€‚")
def cleanup_duplicate_sites(
    ctx: typer.Context,
):
    """
    æ¸…ç†æ•¸æ“šåº«ä¸­ 'sc-domain:sc-domain:...' å½¢å¼çš„é‡è¤‡ç«™é»žã€‚
    """
    db: Database = ctx.obj.db_service()
    console.print("[yellow]æ­£åœ¨é–‹å§‹æ¸…ç†é‡è¤‡ç«™é»ž...[/yellow]")
    cleaned_count = db.cleanup_duplicate_domains()
    console.print(f"[green]âœ… æ¸…ç†å®Œæˆï¼å…±æ›´æ–°äº† {cleaned_count} å€‹ç«™é»žã€‚[/green]")


@site_app.command("deactivate-prefixes", help="åœç”¨å·²å­˜åœ¨å°æ‡‰ sc-domain ç‰ˆæœ¬çš„ç¶²å€å‰ç½®å­—å…ƒç«™é»žã€‚")
def deactivate_prefix_sites(
    ctx: typer.Context,
    dry_run: bool = typer.Option(False, "--dry-run", help="åªé¡¯ç¤ºå°‡è¢«åœç”¨çš„ç«™é»žï¼Œä¸åŸ·è¡Œä»»ä½•æ“ä½œã€‚")
):
    """
    å°‡æ‰€æœ‰å·²å­˜åœ¨å°æ‡‰ sc-domain ç‰ˆæœ¬çš„ç¶²å€å‰ç½®å­—å…ƒç«™é»žè¨­ç½®ç‚º is_active = Falseã€‚
    é€™æœ‰åŠ©æ–¼æ¸…ç†æ•¸æ“šåº«ï¼Œé¿å…åŒæ­¥å¤šé¤˜çš„è³‡æºã€‚
    """
    db: Database = ctx.obj.db_service()
    console.print("[yellow]ðŸ” æ­£åœ¨æŸ¥æ‰¾å·²å­˜åœ¨å°æ‡‰ sc-domain çš„å‰ç¶´ç«™é»ž...[/yellow]")

    result = db.deactivate_prefix_sites(dry_run=True)
    
    # é€²è¡Œé¡žåž‹æª¢æŸ¥å’Œæ–·è¨€ï¼Œä»¥è§£æ±º linter éŒ¯èª¤
    import typing
    if not isinstance(result, list):
        console.print(f"[bold red]éŒ¯èª¤ï¼šé æœŸå¾žæ•¸æ“šåº«ç²å–åˆ—è¡¨ï¼Œä½†å¾—åˆ°äº†æ„å¤–çš„é¡žåž‹: {type(result)}[/bold red]")
        raise typer.Exit(1)
    
    sites_to_deactivate: typing.List[typing.Dict[str, typing.Any]] = result

    if not sites_to_deactivate:
        console.print("[green]âœ… æ²’æœ‰æ‰¾åˆ°ä»»ä½•éœ€è¦åœç”¨çš„ç¶²å€å‰ç½®å­—å…ƒç«™é»žã€‚[/green]")
        return

    table = Table(title="å°‡è¢«åœç”¨çš„ç«™é»ž")
    table.add_column("ID", style="cyan")
    table.add_column("Domain", style="magenta")
    for site in sites_to_deactivate:
        table.add_row(str(site['id']), site['domain'])
    console.print(table)

    if dry_run:
        console.print("\n[bold yellow]--dry-run æ¨¡å¼ï¼ŒæœªåŸ·è¡Œä»»ä½•æ“ä½œã€‚[/bold yellow]")
        return

    if typer.confirm("\nä½ ç¢ºå®šè¦åœç”¨ä»¥ä¸Šæ‰€æœ‰ç«™é»žå—Žï¼Ÿ"):
        deactivated_count = db.deactivate_prefix_sites(dry_run=False)
        console.print(f"\n[bold green]âœ… æˆåŠŸåœç”¨äº† {deactivated_count} å€‹ç«™é»žã€‚[/bold green]")
    else:
        console.print("[bold red]æ“ä½œå·²å–æ¶ˆã€‚[/bold red]")


@sync_app.command("daily")
def sync_daily(ctx: typer.Context,
    site_url: Annotated[Optional[str], typer.Option("--site-url")] = None,
    site_id: Annotated[Optional[int], typer.Option("--site-id")] = None,
    all_sites: Annotated[bool, typer.Option("--all-sites")] = False,
    start_date: Annotated[Optional[str], typer.Option("--start-date")] = None,
    end_date: Annotated[Optional[str], typer.Option("--end-date")] = None,
    days: Annotated[int, typer.Option("--days")] = 7,
    retries: Annotated[int, typer.Option()] = 3,
    retry_delay: Annotated[int, typer.Option()] = 5,
    sync_mode: Annotated[SyncMode, typer.Option()] = SyncMode.SKIP,
    resume: Annotated[bool, typer.Option("--resume")] = False,
):
    """å¾ž GSC åŒæ­¥æ¯æ—¥æ•¸æ“šåˆ°æœ¬åœ°æ•¸æ“šåº«ã€‚"""
    db = ctx.obj.db_service()
    client = ctx.obj.gsc_client()
    run_sync(
        db=db,
        client=client,
        site_url=site_url,
        site_id=site_id,
        all_sites=all_sites,
        start_date=start_date,
        end_date=end_date,
        days=days,
        retries=retries,
        retry_delay=retry_delay,
        sync_mode=sync_mode,
        resume=resume,
    )

@analyze_app.command("report")
def analyze_report(ctx: typer.Context,
    site_id: Annotated[int, typer.Option(help="è¦ç”Ÿæˆå ±å‘Šçš„ç¶²ç«™ IDã€‚")],
    output_path: Annotated[str, typer.Option()] = "gsc_report.md",
    days: Annotated[int, typer.Option()] = 30,
    no_plots: Annotated[bool, typer.Option("--no-plots")] = False,
    plot_dir: Annotated[Optional[str], typer.Option()] = None,
):
    """ç”Ÿæˆ GSC æ•¸æ“šåˆ†æžå ±å‘Šã€‚"""
    analysis_service = ctx.obj.analysis_service()
    console.print(f"ðŸš€ é–‹å§‹ç‚ºç«™é»ž ID {site_id} ç”Ÿæˆå ±å‘Š...")
    result = build_report(
        analysis_service=analysis_service,
        site_id=site_id,
        output_path=output_path,
        days=days,
        include_plots=not no_plots,
        plot_save_dir=plot_dir
    )
    if result.get("success"):
        console.print(f"[green]âœ… å ±å‘Šå·²æˆåŠŸç”Ÿæˆæ–¼: {result.get('output_path')}[/green]")
    else:
        errors = result.get('errors', ['æœªçŸ¥éŒ¯èª¤'])
        console.print(f"[red]âŒ å ±å‘Šç”Ÿæˆå¤±æ•—: {', '.join(map(str, errors))}[/red]")

@analyze_app.command("interactive")
def analyze_interactive(ctx: typer.Context,
    site_id: Annotated[Optional[int], typer.Option("--site-id", help="è¦é€²è¡Œå¯è¦–åŒ–åˆ†æžçš„ç¶²ç«™ IDã€‚å¦‚æžœæœªæä¾›ï¼Œå°‡æœƒæç¤ºé¸æ“‡ã€‚")] = None,
    days: Annotated[int, typer.Option("--days", help="è¦åˆ†æžçš„éŽåŽ»å¤©æ•¸ã€‚")] = 30,
):
    """ðŸŽ¨ å•Ÿå‹•äº¤äº’å¼æ•¸æ“šå¯è¦–åŒ–å„€è¡¨æ¿ã€‚"""
    analysis_service = ctx.obj.analysis_service()
    console.print("ðŸŽ¨ å•Ÿå‹•äº¤äº’å¼å¯è¦–åŒ–...", style="cyan")
    visualizer = InteractiveVisualizer(analysis_service)
    visualizer.run(site_id=site_id, days=days)


def _calculate_coverage_percentage(coverage_data: Dict[str, Any]) -> Optional[str]:
    """è¨ˆç®—ä¸¦æ ¼å¼åŒ–æ•¸æ“šè¦†è“‹çŽ‡ç™¾åˆ†æ¯”"""
    first_date_str = coverage_data.get('first_date')
    last_date_str = coverage_data.get('last_date')
    unique_dates = coverage_data.get('unique_dates', 0)

    if first_date_str and last_date_str and unique_dates > 0:
        try:
            first_date = datetime.strptime(first_date_str, '%Y-%m-%d').date()
            last_date = datetime.strptime(last_date_str, '%Y-%m-%d').date()
            total_days = (last_date - first_date).days + 1
            percentage = (unique_dates / total_days) * 100 if total_days > 0 else 0
            return f"{percentage:.1f}% ({unique_dates} / {total_days} å¤©)"
        except (ValueError, TypeError):
            return None
    return None


def _print_coverage_for_site(db: Database, site: Dict[str, Any]):
    """ç‚ºå–®ä¸€ç«™é»žæ‰“å°æ•¸æ“šè¦†è“‹çŽ‡å ±å‘Šçš„è¼”åŠ©å‡½æ•¸ã€‚"""
    site_id = site['id']
    console.print(Panel(f"[bold cyan]æ•¸æ“šè¦†è“‹çŽ‡å ±å‘Š: {site['name']} (ID: {site_id})[/bold cyan]", expand=False))

    # --- æ¯æ—¥æ•¸æ“šè¦†è“‹çŽ‡ ---
    console.print("\n[bold green]ðŸ“Š æ¯æ—¥æ•¸æ“š (Daily Data)[/bold green]")
    daily_coverage = db.get_daily_data_coverage(site_id)
    daily_table = Table(show_header=False, box=None)
    daily_table.add_column(style="magenta")
    daily_table.add_column(style="white")
    total_records_daily = daily_coverage.get('total_records')
    if total_records_daily and total_records_daily > 0:
        daily_table.add_row("ç¸½è¨˜éŒ„æ•¸:", f"{total_records_daily:,}")
        daily_table.add_row("é¦–å€‹æ•¸æ“šæ—¥æœŸ:", str(daily_coverage.get('first_date')))
        daily_table.add_row("æœ€å¾Œæ•¸æ“šæ—¥æœŸ:", str(daily_coverage.get('last_date')))
        daily_table.add_row("æ•¸æ“šè¦†è“‹å¤©æ•¸:", str(daily_coverage.get('unique_dates')))
        coverage_str = _calculate_coverage_percentage(daily_coverage)
        if coverage_str:
            daily_table.add_row("æ™‚é–“è¦†è“‹çŽ‡:", f"[bold cyan]{coverage_str}[/bold cyan]")
    else:
        daily_table.add_row("ç‹€æ…‹:", "[yellow]ç„¡æ¯æ—¥æ•¸æ“š[/yellow]")
    console.print(daily_table)

    # --- æ¯å°æ™‚æ•¸æ“šè¦†è“‹çŽ‡ ---
    console.print("\n[bold green]ðŸ•’ æ¯å°æ™‚æ•¸æ“š (Hourly Data)[/bold green]")
    hourly_coverage = db.get_hourly_data_coverage(site_id)
    
    hourly_table = Table(show_header=False, box=None)
    hourly_table.add_column(style="magenta")
    hourly_table.add_column(style="white")
    total_records_hourly = hourly_coverage.get('total_records')
    if total_records_hourly and total_records_hourly > 0:
        hourly_table.add_row("ç¸½è¨˜éŒ„æ•¸:", f"{total_records_hourly:,}")
        hourly_table.add_row("é¦–å€‹æ•¸æ“šæ—¥æœŸ:", str(hourly_coverage.get('first_date')))
        hourly_table.add_row("æœ€å¾Œæ•¸æ“šæ—¥æœŸ:", str(hourly_coverage.get('last_date')))
        hourly_table.add_row("æ•¸æ“šè¦†è“‹å¤©æ•¸:", str(hourly_coverage.get('unique_dates')))
        coverage_str = _calculate_coverage_percentage(hourly_coverage)
        if coverage_str:
            hourly_table.add_row("æ™‚é–“è¦†è“‹çŽ‡:", f"[bold cyan]{coverage_str}[/bold cyan]")
    else:
        hourly_table.add_row("ç‹€æ…‹:", "[yellow]ç„¡æ¯å°æ™‚æ•¸æ“š[/yellow]")
    console.print(hourly_table)


@analyze_app.command("coverage")
def analyze_coverage(
    ctx: typer.Context,
    site_id: Annotated[Optional[int], typer.Argument(help="è¦æª¢æŸ¥æ•¸æ“šè¦†è“‹çŽ‡çš„ç«™é»ž IDã€‚")] = None,
    all_sites: Annotated[bool, typer.Option("--all", "-a", help="æª¢æŸ¥æ‰€æœ‰ç«™é»žçš„æ•¸æ“šè¦†è“‹çŽ‡ã€‚")] = False,
):
    """
    æª¢æŸ¥æŒ‡å®šç«™é»žåœ¨æ•¸æ“šåº«ä¸­çš„æ•¸æ“šè¦†è“‹æƒ…æ³ã€‚
    å¯æŒ‡å®šå–®ä¸€ç«™é»ž IDï¼Œæˆ–ä½¿ç”¨ --all æª¢æŸ¥æ‰€æœ‰ç«™é»žã€‚
    """
    container = ctx.obj
    db = container.db_service()

    if not site_id and not all_sites:
        console.print("[bold red]âŒ éŒ¯èª¤ï¼šå¿…é ˆæä¾›ä¸€å€‹ç«™é»ž ID æˆ–ä½¿ç”¨ `--all` é¸é …ã€‚[/bold red]")
        raise typer.Exit(code=1)

    if site_id and all_sites:
        console.print("[bold yellow]âš ï¸ è­¦å‘Šï¼šåŒæ™‚æä¾›äº†ç«™é»ž ID å’Œ `--all` é¸é …ï¼Œå°‡å„ªå…ˆè™•ç†æ‰€æœ‰ç«™é»žã€‚[/bold yellow]")
        site_id = None

    sites_to_process = []
    if all_sites:
        sites_to_process = db.get_sites(active_only=False)
        if not sites_to_process:
            console.print("[yellow]æ•¸æ“šåº«ä¸­æ²’æœ‰ä»»ä½•ç«™é»žã€‚[/yellow]")
            return
    elif site_id:
        site = db.get_site_by_id(site_id)
        if not site:
            console.print(f"[bold red]âŒ éŒ¯èª¤ï¼šåœ¨æ•¸æ“šåº«ä¸­æ‰¾ä¸åˆ° ID ç‚º {site_id} çš„ç«™é»žã€‚[/bold red]")
            raise typer.Exit(code=1)
        sites_to_process.append(site)
    
    for i, site in enumerate(sites_to_process):
        if i > 0:
            console.print("\n" + "â”€" * 60 + "\n")
        _print_coverage_for_site(db, site)


@analyze_app.command("compare")
def compare_performance(ctx: typer.Context,
    site_id: Annotated[int, typer.Argument(help="è¦æ¯”è¼ƒçš„ç«™é»ž IDã€‚")],
    period1_start: Annotated[str, typer.Argument(help="ç¬¬ä¸€æ™‚æ®µé–‹å§‹æ—¥æœŸ (YYYY-MM-DD)ã€‚")],
    period1_end: Annotated[str, typer.Argument(help="ç¬¬ä¸€æ™‚æ®µçµæŸæ—¥æœŸ (YYYY-MM-DD)ã€‚")],
    period2_start: Annotated[str, typer.Argument(help="ç¬¬äºŒæ™‚æ®µé–‹å§‹æ—¥æœŸ (YYYY-MM-DD)ã€‚")],
    period2_end: Annotated[str, typer.Argument(help="ç¬¬äºŒæ™‚æ®µçµæŸæ—¥æœŸ (YYYY-MM-DD)ã€‚")],
    group_by: Annotated[str, typer.Option(help="åˆ†çµ„ä¾æ“š ('query' æˆ– 'page')")] = "query",
    limit: Annotated[int, typer.Option()] = 10,
):
    """æ¯”è¼ƒå…©å€‹æ™‚é–“æ®µçš„æ€§èƒ½æ•¸æ“šã€‚"""
    analysis_service = ctx.obj.analysis_service()
    data = analysis_service.compare_performance_periods(
        site_id=site_id,
        period1_start=period1_start,
        period1_end=period1_end,
        period2_start=period2_start,
        period2_end=period2_end,
        group_by=group_by,
        limit=limit,
    )

    if not data:
        console.print("[yellow]æ²’æœ‰æ‰¾åˆ°å¯ç”¨æ–¼æ¯”è¼ƒçš„æ•¸æ“šã€‚[/yellow]")
        return

    table = Table(title=f"æ€§èƒ½å°æ¯”: {group_by.capitalize()} è¡¨ç¾ Top {limit}")
    table.add_column("æŽ’å", style="cyan")
    table.add_column(group_by.capitalize(), style="magenta", max_width=50, overflow="ellipsis")
    table.add_column("é»žæ“Šè®ŠåŒ– (Î”)", style="green", justify="right")
    table.add_column("æ›å…‰è®ŠåŒ– (Î”)", style="blue", justify="right")
    table.add_column("æŽ’åè®ŠåŒ– (Î”)", style="red", justify="right")
    table.add_column("è©³æƒ… (æ™‚æ®µ1 -> æ™‚æ®µ2)", style="dim")

    for i, item in enumerate(data):
        pos_change = item['position_change']
        pos_str = f"{pos_change:+.2f}" if pos_change is not None else "N/A"
        
        table.add_row(
            str(i + 1),
            item['item'],
            f"{item['clicks_change']:+.0f}",
            f"{item['impressions_change']:+.0f}",
            pos_str,
            f"é»žæ“Š: {item['period1_clicks'] or 0:.0f} -> {item['period2_clicks'] or 0:.0f}",
        )
    console.print(table)
