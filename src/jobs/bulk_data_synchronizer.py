#!/usr/bin/env python3
"""
GSC æ•¸æ“šåŒæ­¥ä½œæ¥­
- å·²é‡æ§‹ç‚ºå¯ç›´æ¥èª¿ç”¨çš„å‡½æ•¸ã€‚
- åŒ…å«é€²åº¦æ¢ã€é‡è©¦ã€æ–·é»çºŒå‚³å’Œå¤šç¨®åŒæ­¥æ¨¡å¼ã€‚
"""
import logging
import time
import traceback
from datetime import datetime, timedelta
from typing import List, Optional, Dict, Any

from rich.console import Console
from rich.progress import Progress, SpinnerColumn, TextColumn, BarColumn, TimeElapsedColumn, TimeRemainingColumn
from rich.panel import Panel
from rich.table import Table
import typer

from ..services.gsc_client import GSCClient
from ..services.database import Database, SyncMode
from ..utils.state_manager import StateManager

logger = logging.getLogger("rich")
console = Console()

def run_sync(
    db: Database,
    client: GSCClient,
    site_url: Optional[str],
    site_id: Optional[int],
    all_sites: bool,
    start_date: Optional[str],
    end_date: Optional[str],
    days: int,
    retries: int,
    retry_delay: int,
    sync_mode: SyncMode,
    resume: bool,
):
    """
    åŸ·è¡Œ GSC æ•¸æ“šçš„æ¯æ—¥åŒæ­¥ä½œæ¥­ã€‚
    """
    date_list = _get_sync_dates(start_date, end_date, days)
    sites_to_sync = _get_sites_to_sync(db, site_url, site_id, all_sites)

    start_site_index, start_date_index = 0, 0
    
    if resume:
        state = StateManager.load_sync_state()
        if state:
            current_site_ids = [s['id'] for s in sites_to_sync]
            if state.get('sites_to_sync_ids') == current_site_ids:
                try:
                    last_site_id = state.get('last_successful_site_id')
                    last_date = state.get('last_successful_date')
                    
                    if last_site_id is not None:
                        start_site_index = next(i for i, s in enumerate(sites_to_sync) if s['id'] == last_site_id)
                    
                    if last_date is not None and last_date != "start":
                        start_date_index = date_list.index(last_date) + 1
                    
                    if start_date_index >= len(date_list):
                        start_site_index += 1
                        start_date_index = 0

                    if start_site_index < len(sites_to_sync):
                        resume_site_name = sites_to_sync[start_site_index]['name']
                        resume_date = date_list[start_date_index]
                        logger.info(f"[bold yellow]ğŸ”„ ä»»å‹™æ¢å¾©ä¸­...[/bold yellow] å°‡å¾ç«™é» '{resume_site_name}' çš„æ—¥æœŸ '{resume_date}' é–‹å§‹ã€‚")
                    else:
                        logger.info("[bold green]âœ… æ‰€æœ‰ä»»å‹™éƒ½å·²åœ¨ä¹‹å‰çš„æœƒè©±ä¸­å®Œæˆã€‚[/bold green]")
                        return
                except (ValueError, StopIteration):
                    logger.warning("[bold yellow]âš ï¸ ç„¡æ³•è§£ææ¢å¾©ç‹€æ…‹ï¼Œå°‡å¾é ­é–‹å§‹ã€‚[/bold yellow]")
                    start_site_index, start_date_index = 0, 0
        else:
                logger.info("[bold yellow]âš ï¸ åŒæ­¥ç›®æ¨™å·²æ”¹è®Šï¼Œæ¢å¾©ç‹€æ…‹å·²é‡ç½®ã€‚[/bold yellow]")

    total_days_to_sync = len(date_list) * len(sites_to_sync)
    completed_days = start_site_index * len(date_list) + start_date_index
    
    progress = Progress(
        SpinnerColumn(), TextColumn("[progress.description]{task.description}"), BarColumn(),
        TextColumn("[progress.percentage]{task.percentage:>3.0f}%"), TimeElapsedColumn(), TimeRemainingColumn(),
        console=console
    )
    
    total_stats = {'inserted': 0, 'updated': 0, 'skipped': 0, 'failed': 0}

    try:
        with progress:
            task = progress.add_task("[green]åŒæ­¥é€²åº¦...", total=total_days_to_sync, completed=completed_days)
            for i in range(start_site_index, len(sites_to_sync)):
                site = sites_to_sync[i]
                current_site_stats = {'inserted': 0, 'updated': 0, 'skipped': 0, 'failed': 0}
                site_name = site['name']
                
                start_j = start_date_index if i == start_site_index else 0
                for j in range(start_j, len(date_list)):
                    date = date_list[j]
                    progress.update(task, description=f"åŒæ­¥ [{site_name}] æ—¥æœŸ [{date}]")
                    
                    if sync_mode.value == "replace":
                        db.delete_performance_data_for_day(site['id'], date)

                    for attempt in range(retries):
                        try:
                            day_stats = {'inserted': 0, 'updated': 0, 'skipped': 0}
                            data_stream = client.stream_site_data(
                                site_url=site['domain'],
                                start_date=date,
                                end_date=date
                            )
                            
                            for device, search_type, chunk in data_stream:
                                chunk_stats = db.save_data_chunk(
                                    chunk=chunk,
                                    site_id=site['id'],
                                    sync_mode=sync_mode.value,
                                    date_str=date,
                                    device=device,
                                    search_type=search_type
                                )
                                for key in day_stats:
                                    day_stats[key] += chunk_stats.get(key, 0)

                            for key in total_stats:
                                total_stats[key] += day_stats.get(key, 0)
                                current_site_stats[key] += day_stats.get(key, 0)
                            
                            logger.info(
                                f"ç«™é» [bold cyan]{site_name}[/bold cyan] æ—¥æœŸ [bold]{date}[/bold] "
                                f"- [green]æ’å…¥: {day_stats.get('inserted', 0)}[/green], "
                                f"[blue]æ›´æ–°: {day_stats.get('updated', 0)}[/blue], "
                                f"[yellow]è·³é: {day_stats.get('skipped', 0)}[/yellow]"
                            )
                            StateManager.save_sync_state({
                                'last_successful_site_id': site['id'],
                                'last_successful_date': date,
                                'sites_to_sync_ids': [s['id'] for s in sites_to_sync]
                            })
                            break
                        except Exception as e:
                            logger.error(f"åŒæ­¥ç«™é» {site_name} æ—¥æœŸ {date} ç¬¬ {attempt + 1} æ¬¡å˜—è©¦å¤±æ•—: {e}")
                            if attempt == retries - 1:
                                total_stats['failed'] += 1
                                current_site_stats['failed'] += 1
                                logger.error(f"ç«™é» [bold red]{site_name}[/bold red] æ—¥æœŸ [bold red]{date}[/bold red] åœ¨ {retries} æ¬¡é‡è©¦å¾Œæœ€çµ‚å¤±æ•—ã€‚")
                                logger.debug(traceback.format_exc())
                            else:
                                time.sleep(retry_delay)
                    progress.advance(task)

    except Exception as e:
        logger.error(f"åŒæ­¥éç¨‹ä¸­ç™¼ç”Ÿæ„å¤–éŒ¯èª¤: {e}")
    finally:
        console.print(Panel("[bold green]åŒæ­¥ä»»å‹™å®Œæˆ[/bold green]", title="ç¸½çµ"))
        summary_table = Table(title="åŒæ­¥çµæœçµ±è¨ˆ")
        summary_table.add_column("é …ç›®", style="cyan")
        summary_table.add_column("æ•¸é‡", style="magenta", justify="right")
        summary_table.add_row("æ’å…¥è¨˜éŒ„", str(total_stats['inserted']))
        summary_table.add_row("æ›´æ–°è¨˜éŒ„", str(total_stats['updated']))
        summary_table.add_row("è·³éè¨˜éŒ„", str(total_stats['skipped']))
        summary_table.add_row("å¤±æ•—å¤©æ•¸", str(total_stats['failed']))
        console.print(summary_table)


def _get_sync_dates(start_date: Optional[str], end_date: Optional[str], days: int) -> List[str]:
    """æ ¹æ“šè¼¸å…¥åƒæ•¸ç”Ÿæˆæ—¥æœŸåˆ—è¡¨"""
    try:
        end_dt = datetime.strptime(end_date, '%Y-%m-%d') if end_date else datetime.now() - timedelta(days=1)
        start_dt = datetime.strptime(start_date, '%Y-%m-%d') if start_date else end_dt - timedelta(days=days - 1)
    except ValueError:
        logger.error("âŒ æ—¥æœŸæ ¼å¼éŒ¯èª¤ï¼Œè«‹ä½¿ç”¨ YYYY-MM-DD")
        raise typer.Exit(1)

    if start_dt > end_dt:
        logger.error(f"âŒ é–‹å§‹æ—¥æœŸ ({start_dt.date()}) ä¸èƒ½æ™šæ–¼çµæŸæ—¥æœŸ ({end_dt.date()})")
        raise typer.Exit(1)
        
    return [(start_dt + timedelta(days=x)).strftime('%Y-%m-%d') for x in range((end_dt - start_dt).days + 1)]


def _get_sites_to_sync(
    database: Database,
    site_url: Optional[str],
    site_id: Optional[int],
    all_sites: bool
) -> List[Dict[str, Any]]:
    """æ ¹æ“šè¼¸å…¥åƒæ•¸ç²å–è¦åŒæ­¥çš„ç«™é»åˆ—è¡¨"""
    sites_to_sync: List[Dict[str, Any]] = []
    all_db_sites = database.get_sites(active_only=True)

    if all_sites:
        sites_to_sync = all_db_sites
    elif site_id:
        site = next((s for s in all_db_sites if s['id'] == site_id), None)
        if site:
            sites_to_sync.append(site)
    elif site_url:
        site = next((s for s in all_db_sites if s['domain'] == site_url), None)
        if not site:
            logger.info(f"ç«™é» {site_url} ä¸åœ¨æ•¸æ“šåº«ä¸­ï¼Œå˜—è©¦è‡ªå‹•æ·»åŠ ...")
            site_name = site_url.replace('sc-domain:', '').replace('https://', '').replace('http://', '').rstrip('/')
            try:
                new_site_id = database.add_site(domain=site_url, name=site_name)
                all_db_sites = database.get_sites(active_only=True)
                site = next((s for s in all_db_sites if s['id'] == new_site_id), None)
                if site:
                    logger.info(f"âœ… ç«™é»è‡ªå‹•æ·»åŠ æˆåŠŸï¼ID: {new_site_id}")
            except Exception as e:
                logger.error(f"è‡ªå‹•æ·»åŠ ç«™é» {site_url} å¤±æ•—: {e}")
                site = None
        if site:
            sites_to_sync.append(site)

    if not sites_to_sync:
        logger.error("âŒ æœªæ‰¾åˆ°æˆ–æŒ‡å®šä»»ä½•è¦åŒæ­¥çš„ç«™é»")
        raise typer.Exit(1)
    return sites_to_sync
