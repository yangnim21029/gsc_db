#!/usr/bin/env python3
"""
GSC åˆ†æå ±å‘Šæ§‹å»ºå™¨
é‡æ§‹ç‚ºå¯èª¿ç”¨å‡½æ•¸ï¼Œæ”¯æŒ CLI æ•´åˆ
"""

import sqlite3
import matplotlib.pyplot as plt
import pandas as pd
import argparse
from datetime import datetime, timedelta
import os
import seaborn as sns
from pathlib import Path
from typing import Optional, Dict, Any, List
import logging

# å°ˆæ¡ˆæ¨¡çµ„å°å…¥
from .. import config

# è¨­ç½®æ—¥èªŒ
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# è¨­ç½®ç¾ä»£åŒ–è¦–è¦ºé¢¨æ ¼ - åƒè€ƒ Uber/Duolingo è¨­è¨ˆ
plt.style.use('seaborn-v0_8-whitegrid')
plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'Helvetica', 'SimHei']
plt.rcParams['axes.unicode_minus'] = False
plt.rcParams['figure.facecolor'] = 'white'
plt.rcParams['axes.facecolor'] = '#f8f9fa'
plt.rcParams['axes.spines.top'] = False
plt.rcParams['axes.spines.right'] = False
plt.rcParams['axes.spines.left'] = False
plt.rcParams['axes.spines.bottom'] = False
plt.rcParams['grid.color'] = '#e9ecef'
plt.rcParams['grid.linewidth'] = 0.8
plt.rcParams['grid.alpha'] = 0.7

# Uber/Duolingo é¢¨æ ¼çš„é…è‰²æ–¹æ¡ˆ
UBER_COLORS = {
    'primary': '#000000',
    'secondary': '#5c6ac4',
    'success': '#06d6a0',
    'warning': '#ffd166',
    'danger': '#ef476f',
    'info': '#118ab2',
    'light': '#f8f9fa',
    'dark': '#343a40'
}

DUOLINGO_COLORS = {
    'green': '#58cc02',
    'blue': '#1cb0f6',
    'red': '#ff4b4b',
    'yellow': '#ffc800',
    'purple': '#ce82ff',
    'orange': '#ff9600'
}


class GSCVisualizer:
    """GSC æ•¸æ“šå¯è¦–åŒ–å™¨"""

    def __init__(self, db_path: str = str(config.DB_PATH)):
        self.db_path = db_path or str(config.DB_PATH)

    def get_daily_stats(self, days=30):
        """ç²å–æ¯æ—¥çµ±è¨ˆæ•¸æ“š"""
        try:
            conn = sqlite3.connect(self.db_path)

            # å…ˆç²å–æ•¸æ“šåº«ä¸­çš„å¯¦éš›æ—¥æœŸç¯„åœ
            cursor = conn.execute("SELECT MAX(date) FROM daily_rankings")
            latest_date_str = cursor.fetchone()[0]

            if not latest_date_str:
                print("æ•¸æ“šåº«ä¸­æ²’æœ‰æ•¸æ“š")
                conn.close()
                return None

            # ä»¥æ•¸æ“šåº«ä¸­çš„æœ€æ–°æ—¥æœŸç‚ºåŸºæº–è¨ˆç®—ç¯„åœ
            latest_date = datetime.strptime(latest_date_str, '%Y-%m-%d').date()
            start_date = latest_date - timedelta(days=days - 1)

            query = """
            SELECT date,
                   SUM(clicks) as total_clicks,
                   SUM(impressions) as total_impressions,
                   AVG(position) as avg_position,
                   COUNT(*) as keyword_count
            FROM daily_rankings
            WHERE date >= ? AND date <= ?
            GROUP BY date
            ORDER BY date
            """

            df = pd.read_sql_query(
                query, conn, params=(
                    start_date, latest_date))
            conn.close()

            # è½‰æ›æ—¥æœŸæ ¼å¼
            df['date'] = pd.to_datetime(df['date'])

            return df

        except Exception as e:
            logger.error(f"ç²å–æ•¸æ“šéŒ¯èª¤: {e}")
            return None

    def get_top_keywords(self, limit=20, days=7):
        """ç²å–è¡¨ç¾æœ€ä½³çš„é—œéµå­—"""
        try:
            conn = sqlite3.connect(self.db_path)

            # ç²å–æ•¸æ“šåº«ä¸­çš„æœ€æ–°æ—¥æœŸ
            cursor = conn.execute("SELECT MAX(date) FROM daily_rankings")
            latest_date_str = cursor.fetchone()[0]
            if not latest_date_str:
                conn.close()
                return None

            latest_date = datetime.strptime(latest_date_str, '%Y-%m-%d').date()
            start_date = latest_date - timedelta(days=days - 1)

            query = """
            SELECT query as keyword,
                   SUM(clicks) as total_clicks,
                   SUM(impressions) as total_impressions,
                   AVG(position) as avg_position,
                   AVG(ctr) as avg_ctr
            FROM daily_rankings
            WHERE date >= ? AND date <= ?
            GROUP BY query
            ORDER BY total_clicks DESC
            LIMIT ?
            """

            df = pd.read_sql_query(
                query, conn, params=(
                    start_date, latest_date, limit))
            conn.close()

            return df

        except Exception as e:
            logger.error(f"ç²å–é—œéµå­—æ•¸æ“šéŒ¯èª¤: {e}")
            return None

    def get_page_performance(self, limit=15, days=7):
        """ç²å–é é¢è¡¨ç¾æ•¸æ“š"""
        try:
            conn = sqlite3.connect(self.db_path)

            # ç²å–æ•¸æ“šåº«ä¸­çš„æœ€æ–°æ—¥æœŸ
            cursor = conn.execute("SELECT MAX(date) FROM page_data")
            latest_date_str = cursor.fetchone()[0]
            if not latest_date_str:
                conn.close()
                return None

            latest_date = datetime.strptime(latest_date_str, '%Y-%m-%d').date()
            start_date = latest_date - timedelta(days=days - 1)

            query = """
            SELECT page,
                   SUM(clicks) as total_clicks,
                   SUM(impressions) as total_impressions,
                   AVG(position) as avg_position,
                   AVG(ctr) as avg_ctr
            FROM page_data
            WHERE date >= ? AND date <= ?
            GROUP BY page
            ORDER BY total_clicks DESC
            LIMIT ?
            """

            df = pd.read_sql_query(
                query, conn, params=(
                    start_date, latest_date, limit))
            conn.close()

            # ç°¡åŒ–é é¢è·¯å¾‘ä»¥ä¾¿é¡¯ç¤º
            def clean_page_url(url):
                import urllib.parse
                try:
                    # URL decode è™•ç†ä¸­æ–‡
                    decoded_url = urllib.parse.unquote(url, encoding='utf-8')

                    # æå–æœ‰æ„ç¾©çš„éƒ¨åˆ†
                    if '/' in decoded_url:
                        # å–æœ€å¾Œä¸€å€‹è·¯å¾‘æ®µ
                        last_part = decoded_url.split('/')[-1]
                        # å¦‚æœæ˜¯ç©ºçš„ï¼Œå–å€’æ•¸ç¬¬äºŒå€‹
                        if not last_part and len(decoded_url.split('/')) > 1:
                            last_part = decoded_url.split('/')[-2]
                    else:
                        last_part = decoded_url

                    # ç§»é™¤æŸ¥è©¢åƒæ•¸
                    if '?' in last_part:
                        last_part = last_part.split('?')[0]

                    # é™åˆ¶é•·åº¦
                    if len(last_part) > 35:
                        last_part = last_part[:32] + '...'

                    return last_part if last_part else 'é¦–é '
                except BaseException:
                    # å¦‚æœè§£ç¢¼å¤±æ•—ï¼Œä½¿ç”¨åŸå§‹æ–¹æ³•
                    short = url.split('/')[-1] if '/' in url else url
                    return short[:35] if len(short) > 35 else short

            df['page_short'] = df['page'].apply(clean_page_url)
            return df

        except Exception as e:
            logger.error(f"ç²å–é é¢æ•¸æ“šéŒ¯èª¤: {e}")
            return None

    def plot_daily_trends(self, days=30, save_path=None):
        """ç¹ªè£½æ¯æ—¥è¶¨å‹¢åœ–"""
        df = self.get_daily_stats(days)
        if df is None or df.empty:
            print("æ²’æœ‰æ•¸æ“šå¯ä¾›ç¹ªè£½")
            return None

        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        fig.suptitle(f'GSC æ•¸æ“šè¶¨å‹¢åˆ†æ ({days} å¤©)', fontsize=16, fontweight='bold')

        # é»æ“Šæ•¸è¶¨å‹¢
        axes[0, 0].plot(df['date'], df['total_clicks'], 
                       color=DUOLINGO_COLORS['blue'], linewidth=2.5, marker='o')
        axes[0, 0].set_title('æ¯æ—¥é»æ“Šæ•¸', fontweight='bold')
        axes[0, 0].set_ylabel('é»æ“Šæ•¸')
        axes[0, 0].grid(True, alpha=0.3)

        # å±•ç¤ºæ•¸è¶¨å‹¢
        axes[0, 1].plot(df['date'], df['total_impressions'], 
                       color=DUOLINGO_COLORS['green'], linewidth=2.5, marker='s')
        axes[0, 1].set_title('æ¯æ—¥å±•ç¤ºæ•¸', fontweight='bold')
        axes[0, 1].set_ylabel('å±•ç¤ºæ•¸')
        axes[0, 1].grid(True, alpha=0.3)

        # å¹³å‡æ’åè¶¨å‹¢
        axes[1, 0].plot(df['date'], df['avg_position'], 
                       color=DUOLINGO_COLORS['orange'], linewidth=2.5, marker='^')
        axes[1, 0].set_title('å¹³å‡æ’å', fontweight='bold')
        axes[1, 0].set_ylabel('æ’å')
        axes[1, 0].invert_yaxis()  # æ’åè¶Šå°è¶Šå¥½
        axes[1, 0].grid(True, alpha=0.3)

        # é—œéµå­—æ•¸é‡è¶¨å‹¢
        axes[1, 1].plot(df['date'], df['keyword_count'], 
                       color=DUOLINGO_COLORS['purple'], linewidth=2.5, marker='d')
        axes[1, 1].set_title('é—œéµå­—æ•¸é‡', fontweight='bold')
        axes[1, 1].set_ylabel('é—œéµå­—æ•¸')
        axes[1, 1].grid(True, alpha=0.3)

        # æ ¼å¼åŒ–æ—¥æœŸè»¸
        for ax in axes.flat:
            ax.tick_params(axis='x', rotation=45)
            ax.set_xlabel('æ—¥æœŸ')

        plt.tight_layout()

        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"åœ–è¡¨å·²ä¿å­˜åˆ°: {save_path}")
        else:
            plt.show()

        return fig

    def plot_top_keywords(self, limit=20, days=7, save_path=None):
        """ç¹ªè£½é ‚ç´šé—œéµå­—åœ–è¡¨"""
        df = self.get_top_keywords(limit, days)
        if df is None or df.empty:
            print("æ²’æœ‰é—œéµå­—æ•¸æ“šå¯ä¾›ç¹ªè£½")
            return None

        fig, axes = plt.subplots(2, 2, figsize=(16, 12))
        fig.suptitle(f'é ‚ç´šé—œéµå­—åˆ†æ (å‰ {limit} å)', fontsize=16, fontweight='bold')

        # é»æ“Šæ•¸å‰10å
        top_clicks = df.head(10)
        axes[0, 0].barh(range(len(top_clicks)), top_clicks['total_clicks'], 
                       color=DUOLINGO_COLORS['blue'])
        axes[0, 0].set_yticks(range(len(top_clicks)))
        axes[0, 0].set_yticklabels(top_clicks['keyword'])
        axes[0, 0].set_title('é»æ“Šæ•¸ Top 10', fontweight='bold')
        axes[0, 0].set_xlabel('é»æ“Šæ•¸')

        # å±•ç¤ºæ•¸å‰10å
        top_impressions = df.nlargest(10, 'total_impressions')
        axes[0, 1].barh(range(len(top_impressions)), top_impressions['total_impressions'], 
                       color=DUOLINGO_COLORS['green'])
        axes[0, 1].set_yticks(range(len(top_impressions)))
        axes[0, 1].set_yticklabels(top_impressions['keyword'])
        axes[0, 1].set_title('å±•ç¤ºæ•¸ Top 10', fontweight='bold')
        axes[0, 1].set_xlabel('å±•ç¤ºæ•¸')

        # å¹³å‡æ’åå‰10åï¼ˆæ’åè¶Šå°è¶Šå¥½ï¼‰
        top_position = df.nsmallest(10, 'avg_position')
        axes[1, 0].barh(range(len(top_position)), top_position['avg_position'], 
                       color=DUOLINGO_COLORS['orange'])
        axes[1, 0].set_yticks(range(len(top_position)))
        axes[1, 0].set_yticklabels(top_position['keyword'])
        axes[1, 0].set_title('å¹³å‡æ’å Top 10', fontweight='bold')
        axes[1, 0].set_xlabel('å¹³å‡æ’å')

        # CTR å‰10å
        top_ctr = df.nlargest(10, 'avg_ctr')
        axes[1, 1].barh(range(len(top_ctr)), top_ctr['avg_ctr'] * 100, 
                       color=DUOLINGO_COLORS['purple'])
        axes[1, 1].set_yticks(range(len(top_ctr)))
        axes[1, 1].set_yticklabels(top_ctr['keyword'])
        axes[1, 1].set_title('CTR Top 10', fontweight='bold')
        axes[1, 1].set_xlabel('CTR (%)')

        plt.tight_layout()

        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"åœ–è¡¨å·²ä¿å­˜åˆ°: {save_path}")
        else:
            plt.show()

        return fig

    def plot_page_performance(self, limit=15, days=7, save_path=None):
        """ç¹ªè£½é é¢è¡¨ç¾åœ–è¡¨"""
        df = self.get_page_performance(limit, days)
        if df is None or df.empty:
            print("æ²’æœ‰é é¢æ•¸æ“šå¯ä¾›ç¹ªè£½")
            return None

        fig, axes = plt.subplots(2, 2, figsize=(16, 12))
        fig.suptitle(f'é é¢è¡¨ç¾åˆ†æ (å‰ {limit} å)', fontsize=16, fontweight='bold')

        # é»æ“Šæ•¸å‰10å
        top_clicks = df.head(10)
        axes[0, 0].barh(range(len(top_clicks)), top_clicks['total_clicks'], 
                       color=DUOLINGO_COLORS['blue'])
        axes[0, 0].set_yticks(range(len(top_clicks)))
        axes[0, 0].set_yticklabels(top_clicks['page_short'])
        axes[0, 0].set_title('é é¢é»æ“Šæ•¸ Top 10', fontweight='bold')
        axes[0, 0].set_xlabel('é»æ“Šæ•¸')

        # å±•ç¤ºæ•¸å‰10å
        top_impressions = df.nlargest(10, 'total_impressions')
        axes[0, 1].barh(range(len(top_impressions)), top_impressions['total_impressions'], 
                       color=DUOLINGO_COLORS['green'])
        axes[0, 1].set_yticks(range(len(top_impressions)))
        axes[0, 1].set_yticklabels(top_impressions['page_short'])
        axes[0, 1].set_title('é é¢å±•ç¤ºæ•¸ Top 10', fontweight='bold')
        axes[0, 1].set_xlabel('å±•ç¤ºæ•¸')

        # å¹³å‡æ’åå‰10å
        top_position = df.nsmallest(10, 'avg_position')
        axes[1, 0].barh(range(len(top_position)), top_position['avg_position'], 
                       color=DUOLINGO_COLORS['orange'])
        axes[1, 0].set_yticks(range(len(top_position)))
        axes[1, 0].set_yticklabels(top_position['page_short'])
        axes[1, 0].set_title('é é¢å¹³å‡æ’å Top 10', fontweight='bold')
        axes[1, 0].set_xlabel('å¹³å‡æ’å')

        # CTR å‰10å
        top_ctr = df.nlargest(10, 'avg_ctr')
        axes[1, 1].barh(range(len(top_ctr)), top_ctr['avg_ctr'] * 100, 
                       color=DUOLINGO_COLORS['purple'])
        axes[1, 1].set_yticks(range(len(top_ctr)))
        axes[1, 1].set_yticklabels(top_ctr['page_short'])
        axes[1, 1].set_title('é é¢ CTR Top 10', fontweight='bold')
        axes[1, 1].set_xlabel('CTR (%)')

        plt.tight_layout()

        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"åœ–è¡¨å·²ä¿å­˜åˆ°: {save_path}")
        else:
            plt.show()

        return fig

    def data_summary(self):
        """ç”Ÿæˆæ•¸æ“šæ‘˜è¦"""
        try:
            conn = sqlite3.connect(self.db_path)
            
            # åŸºæœ¬çµ±è¨ˆ
            cursor = conn.execute("SELECT COUNT(*) FROM daily_rankings")
            total_records = cursor.fetchone()[0]
            
            cursor = conn.execute("SELECT COUNT(DISTINCT date) FROM daily_rankings")
            total_days = cursor.fetchone()[0]
            
            cursor = conn.execute("SELECT COUNT(DISTINCT query) FROM daily_rankings")
            total_keywords = cursor.fetchone()[0]
            
            cursor = conn.execute("SELECT COUNT(DISTINCT page) FROM page_data")
            total_pages = cursor.fetchone()[0]
            
            # æœ€æ–°æ•¸æ“šæ—¥æœŸ
            cursor = conn.execute("SELECT MAX(date) FROM daily_rankings")
            latest_date = cursor.fetchone()[0]
            
            conn.close()
            
            return {
                'total_records': total_records,
                'total_days': total_days,
                'total_keywords': total_keywords,
                'total_pages': total_pages,
                'latest_date': latest_date
            }
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆæ•¸æ“šæ‘˜è¦éŒ¯èª¤: {e}")
            return None


def _generate_summary_plot(visualizer: GSCVisualizer, days: int = 30, save_path: Optional[str] = None) -> Optional[plt.Figure]:
    """ç”Ÿæˆæ‘˜è¦åœ–è¡¨"""
    try:
        return visualizer.plot_daily_trends(days=days, save_path=save_path)
    except Exception as e:
        logger.error(f"ç”Ÿæˆæ‘˜è¦åœ–è¡¨å¤±æ•—: {e}")
        return None


def _create_markdown_report(visualizer: GSCVisualizer, days: int = 30, output_path: str = "gsc_report.md") -> bool:
    """å‰µå»º Markdown å ±å‘Š"""
    try:
        # ç²å–æ•¸æ“šæ‘˜è¦
        summary = visualizer.data_summary()
        if not summary:
            logger.error("ç„¡æ³•ç²å–æ•¸æ“šæ‘˜è¦")
            return False

        # ç²å–é—œéµå­—æ•¸æ“š
        keywords_df = visualizer.get_top_keywords(limit=20, days=days)
        pages_df = visualizer.get_page_performance(limit=15, days=days)

        # ç”Ÿæˆå ±å‘Šå…§å®¹
        report_content = f"""# Google Search Console æ•¸æ“šåˆ†æå ±å‘Š

## ğŸ“Š æ•¸æ“šæ¦‚è¦½

- **ç¸½è¨˜éŒ„æ•¸**: {summary['total_records']:,}
- **æ•¸æ“šå¤©æ•¸**: {summary['total_days']} å¤©
- **é—œéµå­—æ•¸é‡**: {summary['total_keywords']:,}
- **é é¢æ•¸é‡**: {summary['total_pages']:,}
- **æœ€æ–°æ•¸æ“šæ—¥æœŸ**: {summary['latest_date']}

## ğŸ¯ åˆ†ææœŸé–“

æœ¬å ±å‘Šåˆ†ææœ€è¿‘ **{days} å¤©** çš„æ•¸æ“šè¡¨ç¾ã€‚

## ğŸ“ˆ é—œéµå­—è¡¨ç¾ Top 20

| æ’å | é—œéµå­— | é»æ“Šæ•¸ | å±•ç¤ºæ•¸ | å¹³å‡æ’å | CTR |
|------|--------|--------|--------|----------|-----|
"""

        if keywords_df is not None and not keywords_df.empty:
            for i, row in keywords_df.head(20).iterrows():
                report_content += f"| {i+1} | {row['keyword']} | {row['total_clicks']:,} | {row['total_impressions']:,} | {row['avg_position']:.1f} | {row['avg_ctr']:.2%} |\n"
        else:
            report_content += "| - | ç„¡æ•¸æ“š | - | - | - | - |\n"

        report_content += f"""

## ğŸ“„ é é¢è¡¨ç¾ Top 15

| æ’å | é é¢ | é»æ“Šæ•¸ | å±•ç¤ºæ•¸ | å¹³å‡æ’å | CTR |
|------|------|--------|--------|----------|-----|
"""

        if pages_df is not None and not pages_df.empty:
            for i, row in pages_df.head(15).iterrows():
                report_content += f"| {i+1} | {row['page_short']} | {row['total_clicks']:,} | {row['total_impressions']:,} | {row['avg_position']:.1f} | {row['avg_ctr']:.2%} |\n"
        else:
            report_content += "| - | ç„¡æ•¸æ“š | - | - | - | - |\n"

        report_content += f"""

## ğŸ“… å ±å‘Šç”Ÿæˆæ™‚é–“

{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

---

*æ­¤å ±å‘Šç”± GSC æ•¸æ“šåˆ†æå·¥å…·è‡ªå‹•ç”Ÿæˆ*
"""

        # ä¿å­˜å ±å‘Š
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(report_content)

        logger.info(f"Markdown å ±å‘Šå·²ä¿å­˜åˆ°: {output_path}")
        return True

    except Exception as e:
        logger.error(f"å‰µå»º Markdown å ±å‘Šå¤±æ•—: {e}")
        return False


def build_report(
    output_path: str = "gsc_report.md",
    days: int = 30,
    include_plots: bool = True,
    plot_save_dir: Optional[str] = None,
    db_path: str = str(config.DB_PATH)
) -> Dict[str, Any]:
    """
    æ§‹å»º GSC æ•¸æ“šåˆ†æå ±å‘Š
    
    Args:
        output_path: å ±å‘Šè¼¸å‡ºè·¯å¾‘
        days: åˆ†æå¤©æ•¸
        include_plots: æ˜¯å¦åŒ…å«åœ–è¡¨
        plot_save_dir: åœ–è¡¨ä¿å­˜ç›®éŒ„
        db_path: æ•¸æ“šåº«è·¯å¾‘
    
    Returns:
        åŒ…å«å ±å‘Šç”Ÿæˆçµæœçš„å­—å…¸
    """
    result = {
        'success': False,
        'report_path': output_path,
        'plots_generated': [],
        'errors': []
    }
    
    try:
        logger.info(f"é–‹å§‹ç”Ÿæˆ GSC æ•¸æ“šåˆ†æå ±å‘Šï¼Œåˆ†æ {days} å¤©æ•¸æ“š...")
        
        # åˆå§‹åŒ–å¯è¦–åŒ–å™¨
        visualizer = GSCVisualizer(db_path)
        
        # æª¢æŸ¥æ•¸æ“šåº«æ˜¯å¦å­˜åœ¨
        if not Path(db_path).exists():
            error_msg = f"æ•¸æ“šåº«æ–‡ä»¶ä¸å­˜åœ¨: {db_path}"
            logger.error(error_msg)
            result['errors'].append(error_msg)
            return result
        
        # ç”Ÿæˆ Markdown å ±å‘Š
        if not _create_markdown_report(visualizer, days, output_path):
            error_msg = "ç”Ÿæˆ Markdown å ±å‘Šå¤±æ•—"
            result['errors'].append(error_msg)
            return result
        
        # ç”Ÿæˆåœ–è¡¨
        if include_plots:
            plot_dir = Path(plot_save_dir) if plot_save_dir else config.ASSETS_DIR
            plot_dir.mkdir(exist_ok=True)
            
            # ç”Ÿæˆæ‘˜è¦åœ–è¡¨
            summary_plot_path = plot_dir / "daily_trends.png"
            if _generate_summary_plot(visualizer, days, str(summary_plot_path)):
                result['plots_generated'].append(str(summary_plot_path))
            
            # ç”Ÿæˆé—œéµå­—åœ–è¡¨
            keywords_plot_path = plot_dir / "top_keywords.png"
            try:
                visualizer.plot_top_keywords(limit=20, days=days, save_path=str(keywords_plot_path))
                result['plots_generated'].append(str(keywords_plot_path))
            except Exception as e:
                logger.error(f"ç”Ÿæˆé—œéµå­—åœ–è¡¨å¤±æ•—: {e}")
                result['errors'].append(f"é—œéµå­—åœ–è¡¨ç”Ÿæˆå¤±æ•—: {e}")
            
            # ç”Ÿæˆé é¢è¡¨ç¾åœ–è¡¨
            pages_plot_path = plot_dir / "page_performance.png"
            try:
                visualizer.plot_page_performance(limit=15, days=days, save_path=str(pages_plot_path))
                result['plots_generated'].append(str(pages_plot_path))
            except Exception as e:
                logger.error(f"ç”Ÿæˆé é¢è¡¨ç¾åœ–è¡¨å¤±æ•—: {e}")
                result['errors'].append(f"é é¢è¡¨ç¾åœ–è¡¨ç”Ÿæˆå¤±æ•—: {e}")
        
        result['success'] = True
        logger.info(f"å ±å‘Šç”Ÿæˆå®Œæˆ: {output_path}")
        
        # æ·»åŠ æ•¸æ“šæ‘˜è¦
        summary = visualizer.data_summary()
        if summary:
            result['summary'] = summary
        
        return result
        
    except Exception as e:
        error_msg = f"ç”Ÿæˆå ±å‘Šæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}"
        logger.error(error_msg)
        result['errors'].append(error_msg)
        return result


def main():
    """ä¸»å‡½æ•¸ - ç”¨æ–¼ç›´æ¥é‹è¡Œè…³æœ¬"""
    parser = argparse.ArgumentParser(description='GSC æ•¸æ“šåˆ†æå ±å‘Šç”Ÿæˆå™¨')
    parser.add_argument('--output', '-o', default='gsc_report.md', 
                       help='è¼¸å‡ºå ±å‘Šæ–‡ä»¶è·¯å¾‘')
    parser.add_argument('--days', '-d', type=int, default=30, 
                       help='åˆ†æå¤©æ•¸ (é»˜èª: 30)')
    parser.add_argument('--no-plots', action='store_true', 
                       help='ä¸ç”Ÿæˆåœ–è¡¨')
    parser.add_argument('--plot-dir', default='assets', 
                       help='åœ–è¡¨ä¿å­˜ç›®éŒ„')
    parser.add_argument('--db', default='gsc_data.db', 
                       help='æ•¸æ“šåº«æ–‡ä»¶è·¯å¾‘')
    
    args = parser.parse_args()
    
    # èª¿ç”¨ä¸»å‡½æ•¸
    result = build_report(
        output_path=args.output,
        days=args.days,
        include_plots=not args.no_plots,
        plot_save_dir=args.plot_dir,
        db_path=args.db
    )
    
    if result['success']:
        print(f"âœ… å ±å‘Šç”ŸæˆæˆåŠŸ: {result['report_path']}")
        if result['plots_generated']:
            print(f"ğŸ“Š ç”Ÿæˆçš„åœ–è¡¨: {', '.join(result['plots_generated'])}")
        if 'summary' in result:
            summary = result['summary']
            print(f"ğŸ“ˆ æ•¸æ“šæ‘˜è¦: {summary['total_records']:,} è¨˜éŒ„, {summary['total_days']} å¤©, {summary['total_keywords']:,} é—œéµå­—")
    else:
        print("âŒ å ±å‘Šç”Ÿæˆå¤±æ•—")
        for error in result['errors']:
            print(f"  - {error}")
        return 1
    
    return 0


if __name__ == "__main__":
    exit(main())
