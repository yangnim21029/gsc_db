#!/usr/bin/env python3
"""
æ€§èƒ½åŸºæº–æ¸¬è©¦
- æ¯”è¼ƒé€è¡Œæ’å…¥èˆ‡æ‰¹é‡ `executemany` çš„æ€§èƒ½å·®ç•°ã€‚
- ä½¿ç”¨ DI å®¹å™¨ä¾†ç²å–ç·šç¨‹å®‰å…¨çš„è³‡æ–™åº«æœå‹™å’Œé€£æ¥ã€‚
"""

import logging
import os
import random
import sqlite3
import sys
import threading
import time
from datetime import datetime, timedelta
from typing import Any, Dict, List

# ç¢ºä¿å°ˆæ¡ˆæ ¹ç›®éŒ„åœ¨ sys.path ä¸­
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

from src.containers import Container
from src.services.database import Database

# è¨­ç½®æ—¥èªŒ
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


def generate_test_hourly_data(count: int) -> List[Dict[str, Any]]:
    """ç”Ÿæˆæ¸¬è©¦ç”¨çš„æ¯å°æ™‚æ•¸æ“š"""
    data = []
    base_date = datetime.now() - timedelta(days=30)

    for i in range(count):
        date = base_date + timedelta(days=i % 30)
        hour = i % 24

        data.append(
            {
                "site_id": random.randint(1, 5),
                "keyword_id": random.randint(1, 100),
                "date": date.strftime("%Y-%m-%d"),
                "hour": hour,
                "hour_timestamp": f"{date.strftime('%Y-%m-%d')}T{hour:02d}:00:00Z",
                "query": f"test keyword {i % 50}",
                "position": random.uniform(1.0, 100.0),
                "clicks": random.randint(0, 1000),
                "impressions": random.randint(0, 10000),
                "ctr": random.uniform(0.0, 0.1),
                "page": f"https://example.com/page-{i % 20}.html",
                "country": "TWN",
                "device": "ALL",
            }
        )

    return data


def benchmark_old_method(
    conn: sqlite3.Connection, lock: threading.Lock, data: List[Dict[str, Any]]
) -> float:
    """æ¸¬è©¦èˆŠçš„é€è¡Œæ’å…¥æ–¹æ³•"""
    start_time = time.time()
    with lock:
        try:
            for ranking in data:
                conn.execute(
                    """
                    INSERT OR REPLACE INTO hourly_rankings
                    (site_id, keyword_id, date, hour, hour_timestamp, query, position,
                     clicks, impressions, ctr, page, country, device)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                """,
                    (
                        ranking["site_id"],
                        ranking.get("keyword_id"),
                        ranking["date"],
                        ranking["hour"],
                        ranking["hour_timestamp"],
                        ranking["query"],
                        ranking.get("position"),
                        ranking.get("clicks", 0),
                        ranking.get("impressions", 0),
                        ranking.get("ctr", 0),
                        ranking.get("page"),
                        ranking.get("country", "TWN"),
                        ranking.get("device", "ALL"),
                    ),
                )
            conn.commit()
        except Exception as e:
            logger.error(f"Failed to save hourly ranking: {e}")
            conn.rollback()

    end_time = time.time()
    return end_time - start_time


def benchmark_new_method(db: Database, data: List[Dict[str, Any]]) -> float:
    """æ¸¬è©¦æ–°çš„æ‰¹é‡æ’å…¥æ–¹æ³•"""
    start_time = time.time()
    db.save_hourly_ranking_data(data)
    end_time = time.time()
    return end_time - start_time


def run_performance_benchmark():
    """é‹è¡Œæ€§èƒ½åŸºæº–æ¸¬è©¦"""
    # 1. åˆå§‹åŒ– DI å®¹å™¨
    container = Container()
    container.wire(modules=[__name__])

    db_service = container.database()
    db_connection = container.db_connection()
    db_lock = container.db_lock()

    # ç¢ºä¿è¡¨å­˜åœ¨
    db_service.init_db()

    # æ¸¬è©¦ä¸åŒå¤§å°çš„æ•¸æ“šé›†
    test_sizes = [100, 500, 1000, 5000]

    print("ğŸš€ æ¯å°æ™‚æ•¸æ“šä¿å­˜æ€§èƒ½åŸºæº–æ¸¬è©¦")
    print("=" * 60)

    results = []

    for size in test_sizes:
        print(f"\nğŸ“Š æ¸¬è©¦æ•¸æ“šé›†å¤§å°: {size:,} æ¢è¨˜éŒ„")

        # ç”Ÿæˆæ¸¬è©¦æ•¸æ“š
        test_data = generate_test_hourly_data(size)

        def cleanup_table():
            with db_lock:
                db_connection.execute(
                    "DELETE FROM hourly_rankings WHERE query LIKE 'test keyword%'"
                )
                db_connection.commit()

        # æ¸¬è©¦æ–°æ–¹æ³•
        cleanup_table()
        new_time = benchmark_new_method(db_service, test_data)

        # æ¸¬è©¦èˆŠæ–¹æ³•
        cleanup_table()
        old_time = benchmark_old_method(db_connection, db_lock, test_data)

        # è¨ˆç®—æ€§èƒ½æå‡
        speedup = old_time / new_time if new_time > 0 else float("inf")

        results.append(
            {
                "size": size,
                "old_time": old_time,
                "new_time": new_time,
                "speedup": speedup,
            }
        )

        print(f"  èˆŠæ–¹æ³•æ™‚é–“: {old_time:.3f} ç§’")
        print(f"  æ–°æ–¹æ³•æ™‚é–“: {new_time:.3f} ç§’")
        print(f"  æ€§èƒ½æå‡: {speedup:.1f}x")

    # ç¸½çµ
    print("\n" + "=" * 60)
    print("ğŸ“ˆ æ€§èƒ½æ¸¬è©¦ç¸½çµ")
    print("=" * 60)

    for result in results:
        print(f"æ•¸æ“šé›† {result['size']:,} æ¢è¨˜éŒ„:")
        print(f"  æ€§èƒ½æå‡: {result['speedup']:.1f}x")
        print(f"  æ™‚é–“ç¯€çœ: {result['old_time'] - result['new_time']:.3f} ç§’")

    # è¨ˆç®—å¹³å‡æ€§èƒ½æå‡
    avg_speedup = sum(r["speedup"] for r in results) / len(results) if results else 0
    print(f"\nğŸ¯ å¹³å‡æ€§èƒ½æå‡: {avg_speedup:.1f}x")

    return results


if __name__ == "__main__":
    run_performance_benchmark()
