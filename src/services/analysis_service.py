#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
å°ˆè²¬è™•ç†æ•¸æ“šåˆ†æžå’Œå ±å‘Šç”Ÿæˆçš„æœå‹™ã€‚
æ­¤æœå‹™ä¾è³´æ–¼ Database æœå‹™ä¾†ç²å–æ•¸æ“šã€‚
"""

import datetime
import logging
from typing import Any, Dict, List, Optional

import matplotlib.pyplot as plt
import pandas as pd
from matplotlib.figure import Figure

from ..utils.matplotlib_utils import set_chinese_font
from .database import Database

logger = logging.getLogger(__name__)


class AnalysisService:
    def __init__(self, db: Database):
        """
        åˆå§‹åŒ–åˆ†æžæœå‹™ã€‚
        :param db: Database çš„ä¸€å€‹å¯¦ä¾‹ï¼Œç”¨æ–¼æ•¸æ“šåº«äº¤äº’ã€‚
        """
        self.db = db

    def _get_date_range_from_days(self, site_id: int, days: int) -> Optional[tuple[str, str]]:
        """å¾žæ•¸æ“šåº«ç²å–æŒ‡å®šç«™é»žçš„æœ€æ–°æ—¥æœŸä¸¦è¨ˆç®—æ—¥æœŸç¯„åœ"""
        try:
            latest_date = self.db.get_latest_date_from_table("gsc_performance_data", site_id)
            if not latest_date:
                logger.warning(
                    f"åœ¨ gsc_performance_data ä¸­æ‰¾ä¸åˆ°ç«™é»ž ID {site_id} çš„æ•¸æ“šï¼Œç„¡æ³•ç¢ºå®šæ—¥æœŸç¯„åœã€‚"
                )
                return None
            end_date = latest_date
            start_date = end_date - datetime.timedelta(days=days - 1)
            return start_date.strftime("%Y-%m-%d"), end_date.strftime("%Y-%m-%d")
        except Exception as e:
            logger.error(f"ç²å–æ—¥æœŸç¯„åœæ™‚å‡ºéŒ¯: {e}", exc_info=True)
            return None

    def get_top_keywords(
        self, site_id: int, days: int, metric: str = "clicks", limit: int = 20
    ) -> List[Dict[str, Any]]:
        """ç²å–æŒ‡å®šæ™‚é–“ç¯„åœå…§è¡¨ç¾æœ€ä½³çš„é—œéµå­—"""
        if metric not in ["clicks", "impressions"]:
            raise ValueError("Metric must be 'clicks' or 'impressions'")

        date_range = self._get_date_range_from_days(site_id, days)
        if not date_range:
            return []
        start_date, end_date = date_range

        query = f"""
            SELECT query, page, SUM(clicks) as total_clicks,
                   SUM(impressions) as total_impressions, AVG(position) as avg_position
            FROM gsc_performance_data
            WHERE site_id = ? AND date BETWEEN ? AND ?
            GROUP BY query, page
            ORDER BY total_{metric} DESC
            LIMIT ?
        """
        with self.db._lock:
            return [
                dict(row)
                for row in self.db._connection.execute(
                    query, (site_id, start_date, end_date, limit)
                ).fetchall()
            ]

    def get_site_performance_summary(self, site_id: int, days: int) -> Dict[str, Any]:
        """ç²å–ç«™é»žåœ¨æŒ‡å®šæ™‚é–“ç¯„åœå…§çš„æ•´é«”è¡¨ç¾æ‘˜è¦"""
        date_range = self._get_date_range_from_days(site_id, days)
        if not date_range:
            return {}
        start_date, end_date = date_range

        query = """
            SELECT
                SUM(clicks) as total_clicks,
                SUM(impressions) as total_impressions,
                AVG(ctr) as avg_ctr,
                AVG(position) as avg_position
            FROM gsc_performance_data
            WHERE site_id = ? AND date BETWEEN ? AND ?
        """
        with self.db._lock:
            summary = self.db._connection.execute(query, (site_id, start_date, end_date)).fetchone()
            return dict(summary) if summary else {}

    def get_daily_performance_summary(self, site_id: int, days: int) -> List[Dict[str, Any]]:
        """ç²å–æŒ‡å®šç«™é»žåœ¨æ™‚é–“ç¯„åœå…§çš„æ¯æ—¥è¡¨ç¾æ‘˜è¦"""
        date_range = self._get_date_range_from_days(site_id, days)
        if not date_range:
            return []
        start_date, end_date = date_range

        query = """
            SELECT
                date,
                SUM(clicks) as total_clicks,
                SUM(impressions) as total_impressions,
                AVG(ctr) as avg_ctr,
                AVG(position) as avg_position
            FROM gsc_performance_data
            WHERE site_id = ? AND date BETWEEN ? AND ?
            GROUP BY date
            ORDER BY date
        """
        with self.db._lock:
            return [
                dict(row)
                for row in self.db._connection.execute(
                    query, (site_id, start_date, end_date)
                ).fetchall()
            ]

    def get_top_pages(
        self, site_id: int, days: int, metric: str = "clicks", limit: int = 20
    ) -> List[Dict[str, Any]]:
        """ç²å–æŒ‡å®šæ™‚é–“ç¯„åœå…§è¡¨ç¾æœ€ä½³çš„é é¢"""
        if metric not in ["clicks", "impressions"]:
            raise ValueError("Metric must be 'clicks' or 'impressions'")

        date_range = self._get_date_range_from_days(site_id, days)
        if not date_range:
            return []
        start_date, end_date = date_range

        query = f"""
            SELECT
                page,
                SUM(clicks) as total_clicks,
                SUM(impressions) as total_impressions,
                AVG(ctr) as avg_ctr,
                AVG(position) as avg_position
            FROM gsc_performance_data
            WHERE site_id = ? AND date BETWEEN ? AND ?
            GROUP BY page
            ORDER BY total_{metric} DESC
            LIMIT ?
        """
        with self.db._lock:
            return [
                dict(row)
                for row in self.db._connection.execute(
                    query, (site_id, start_date, end_date, limit)
                ).fetchall()
            ]

    def get_overall_summary(self, site_id: int, days: int) -> Dict[str, Any]:
        """ç²å–æŒ‡å®šç«™é»žåœ¨æ™‚é–“ç¯„åœå…§çš„æ•´é«”æ•¸æ“šæ‘˜è¦"""
        date_range = self._get_date_range_from_days(site_id, days)
        if not date_range:
            return {}
        start_date, end_date = date_range

        query = """
            SELECT
                COUNT(*) as total_records,
                COUNT(DISTINCT query) as total_keywords,
                COUNT(DISTINCT page) as total_pages,
                MIN(date) as earliest_date,
                MAX(date) as latest_date
            FROM gsc_performance_data
            WHERE site_id = ? AND date BETWEEN ? AND ?
        """
        with self.db._lock:
            summary = self.db._connection.execute(query, (site_id, start_date, end_date)).fetchone()
            return dict(summary) if summary else {}

    def get_keyword_trend(
        self, site_id: int, query_text: str, start_date: str, end_date: str
    ) -> List[Dict[str, Any]]:
        """
        ç²å–å–®å€‹é—œéµå­—åœ¨ä¸€æ®µæ™‚é–“å…§çš„è¡¨ç¾è¶¨å‹¢ã€‚
        å·²é‡æ§‹ç‚ºä½¿ç”¨ gsc_performance_data è¡¨ã€‚
        """
        query = """
            SELECT date, position, clicks, impressions, ctr
            FROM gsc_performance_data
            WHERE site_id = ? AND query = ? AND date BETWEEN ? AND ?
            ORDER BY date
        """
        with self.db._lock:
            return [
                dict(row)
                for row in self.db._connection.execute(
                    query, (site_id, query_text, start_date, end_date)
                ).fetchall()
            ]

    def get_performance_data_for_visualization(
        self,
        site_id: int,
        start_date: str,
        end_date: str,
        group_by: str = "query",
        filter_term: Optional[str] = None,
    ) -> List[Dict[str, Any]]:
        """
        ç‚ºäº¤äº’å¼å¯è¦–åŒ–ç²å–æ€§èƒ½æ•¸æ“šã€‚
        æ­¤æ–¹æ³•å–ä»£äº†èˆŠçš„ get_rankings å’Œ get_page_dataã€‚
        """
        if group_by not in ["query", "page"]:
            raise ValueError("group_by å¿…é ˆæ˜¯ 'query' æˆ– 'page'")

        base_query = f"""
            SELECT
                date,
                {group_by},
                clicks,
                impressions,
                ctr,
                position
            FROM gsc_performance_data
            WHERE site_id = ? AND date BETWEEN ? AND ?
        """
        params: List[Any] = [site_id, start_date, end_date]

        if filter_term:
            base_query += f" AND {group_by} = ?"
            params.append(filter_term)

        base_query += " ORDER BY date"

        with self.db._lock:
            return [
                dict(row)
                for row in self.db._connection.execute(base_query, tuple(params)).fetchall()
            ]

    def compare_performance_periods(
        self,
        site_id: int,
        period1_start: str,
        period1_end: str,
        period2_start: str,
        period2_end: str,
        group_by: str = "query",
        limit: int = 50,
    ) -> List[Dict[str, Any]]:
        """
        æ¯”è¼ƒå…©å€‹ä¸åŒæ™‚é–“æ®µçš„æ€§èƒ½æ•¸æ“šã€‚

        :param site_id: è¦åˆ†æžçš„ç«™é»ž IDã€‚
        :param period1_start: ç¬¬ä¸€å€‹æ™‚é–“æ®µçš„é–‹å§‹æ—¥æœŸ (YYYY-MM-DD)ã€‚
        :param period1_end: ç¬¬ä¸€å€‹æ™‚é–“æ®µçš„çµæŸæ—¥æœŸ (YYYY-MM-DD)ã€‚
        :param period2_start: ç¬¬äºŒå€‹æ™‚é–“æ®µçš„é–‹å§‹æ—¥æœŸ (YYYY-MM-DD)ã€‚
        :param period2_end: ç¬¬äºŒå€‹æ™‚é–“æ®µçš„çµæŸæ—¥æœŸ (YYYY-MM-DD)ã€‚
        :param group_by: åˆ†çµ„ä¾æ“šï¼Œå¯ä»¥æ˜¯ 'query' æˆ– 'page'ã€‚
        :param limit: è¿”å›žçµæžœçš„æ•¸é‡ï¼ŒæŒ‰é»žæ“Šè®ŠåŒ–é‡é™åºæŽ’åˆ—ã€‚
        :return: ä¸€å€‹åŒ…å«æ¯”è¼ƒæ•¸æ“šçš„å­—å…¸åˆ—è¡¨ã€‚
        """
        if group_by not in ["query", "page"]:
            raise ValueError("group_by å¿…é ˆæ˜¯ 'query' æˆ– 'page'")

        query = f"""
            WITH
            period1_data AS (
                SELECT {group_by} AS item, SUM(clicks) AS p1_clicks,
                       SUM(impressions) AS p1_impressions, AVG(position) AS p1_position,
                       AVG(ctr) AS p1_ctr
                FROM gsc_performance_data
                WHERE site_id = ? AND date BETWEEN ? AND ?
                GROUP BY {group_by}
            ),
            period2_data AS (
                SELECT {group_by} AS item, SUM(clicks) AS p2_clicks,
                       SUM(impressions) AS p2_impressions, AVG(position) AS p2_position,
                       AVG(ctr) AS p2_ctr
                FROM gsc_performance_data
                WHERE site_id = ? AND date BETWEEN ? AND ?
                GROUP BY {group_by}
            )
            SELECT
                COALESCE(p1.item, p2.item) AS item,
                COALESCE(p1.p1_clicks, 0) AS period1_clicks,
                COALESCE(p2.p2_clicks, 0) AS period2_clicks,
                (COALESCE(p2.p2_clicks, 0) - COALESCE(p1.p1_clicks, 0)) AS clicks_change,
                COALESCE(p1.p1_impressions, 0) AS period1_impressions,
                COALESCE(p2.p2_impressions, 0) AS period2_impressions,
                (COALESCE(p2.p2_impressions, 0) - COALESCE(p1.p1_impressions, 0))
                AS impressions_change,
                COALESCE(p1.p1_position, 0) AS period1_position,
                COALESCE(p2.p2_position, 0) AS period2_position,
                (COALESCE(p2.p2_position, 999) - COALESCE(p1.p1_position, 999)) AS position_change,
                COALESCE(p1.p1_ctr, 0) AS period1_ctr,
                COALESCE(p2.p2_ctr, 0) AS period2_ctr,
                (COALESCE(p2.p2_ctr, 0) - COALESCE(p1.p1_ctr, 0)) AS ctr_change
            FROM period1_data p1
            FULL OUTER JOIN period2_data p2 ON p1.item = p2.item
            ORDER BY clicks_change DESC
            LIMIT ?
        """
        params = (
            site_id,
            period1_start,
            period1_end,
            site_id,
            period2_start,
            period2_end,
            limit,
        )
        with self.db._lock:
            return [dict(row) for row in self.db._connection.execute(query, params).fetchall()]

    def get_competitor_analysis(
        self, site_id: int, start_date: str, end_date: str, limit: int = 50
    ) -> List[Dict[str, Any]]:
        """ç²å–ç«¶çˆ­å°æ‰‹åˆ†æžæ•¸æ“š"""
        query = """
            SELECT query, COUNT(DISTINCT page) as competitor_count
            FROM gsc_performance_data
            WHERE site_id = ? AND date BETWEEN ? AND ?
            GROUP BY query
            HAVING competitor_count > 1
            ORDER BY competitor_count DESC
            LIMIT ?
        """
        with self.db._lock:
            return [
                dict(row)
                for row in self.db._connection.execute(
                    query, (site_id, start_date, end_date, limit)
                ).fetchall()
            ]

    def get_seasonal_trends(
        self, site_id: int, year: int, metric: str = "clicks"
    ) -> List[Dict[str, Any]]:
        """åˆ†æžæŒ‡å®šå¹´ä»½çš„å­£ç¯€æ€§è¶¨å‹¢ï¼ˆæŒ‰æœˆåˆ†çµ„ï¼‰"""
        if metric not in ["clicks", "impressions"]:
            raise ValueError("Metric must be 'clicks' or 'impressions'")

        query = f"""
            SELECT strftime('%m', date) as month, SUM({metric}) as total_metric
            FROM gsc_performance_data
            WHERE site_id = ? AND strftime('%Y', date) = ?
            GROUP BY month
            ORDER BY month
        """
        with self.db._lock:
            return [
                dict(row)
                for row in self.db._connection.execute(query, (site_id, str(year))).fetchall()
            ]

    def get_keyword_growth_analysis(
        self,
        site_id: int,
        start_date: str,
        end_date: str,
        growth_threshold: float = 0.1,
    ) -> List[Dict[str, Any]]:
        """
        åˆ†æžé—œéµå­—çš„å¢žé•·æƒ…æ³
        æ­¤å¯¦ç¾è¼ƒç‚ºè¤‡é›œï¼Œæ­¤è™•åƒ…ç‚ºä¸€å€‹ç°¡åŒ–çš„æ¡†æž¶
        """
        logger.warning("Keyword growth analysis is a simplified implementation.")
        # åœ¨çœŸå¯¦å ´æ™¯ä¸­ï¼Œéœ€è¦æ¯”è¼ƒå…©å€‹æ™‚é–“æ®µçš„æ•¸æ“š
        return []

    def generate_performance_summary(self, site_id: int, days: int) -> str:
        """
        ç‚ºæŒ‡å®šç«™é»žç”Ÿæˆæ€§èƒ½æ‘˜è¦å ±å‘Šï¼ˆæ–‡å­—æ ¼å¼ï¼‰ã€‚

        Args:
            site_id: ç«™é»ž ID
            days: è¦åˆ†æžçš„å¤©æ•¸

        Returns:
            æ ¼å¼åŒ–çš„æ–‡å­—å ±å‘Š
        """
        # ç²å–åŸºæœ¬çµ±è¨ˆä¿¡æ¯
        summary = self.get_site_performance_summary(site_id, days)
        if not summary:
            return f"ç«™é»ž ID {site_id} åœ¨éŽåŽ» {days} å¤©å…§æ²’æœ‰æ•¸æ“šã€‚"

        # ç²å–é ‚ç´šé—œéµå­—å’Œé é¢
        top_keywords = self.get_top_keywords(site_id, days, limit=10)
        top_pages = self.get_top_pages(site_id, days, limit=10)

        # ç”Ÿæˆå ±å‘Š
        report_lines = [
            f"=== ç«™é»ž ID {site_id} æ€§èƒ½æ‘˜è¦ (éŽåŽ» {days} å¤©) ===",
            "",
            "ðŸ“Š æ•´é«”çµ±è¨ˆ:",
            f"  ç¸½é»žæ“Šæ•¸: {summary.get('total_clicks', 0):,}",
            f"  ç¸½å±•ç¤ºæ•¸: {summary.get('total_impressions', 0):,}",
            f"  å¹³å‡é»žæ“ŠçŽ‡: {summary.get('avg_ctr', 0):.2%}",
            f"  å¹³å‡æŽ’å: {summary.get('avg_position', 0):.1f}",
            "",
        ]

        if top_keywords:
            report_lines.extend(
                [
                    "ðŸ” ç†±é–€é—œéµå­— (æŒ‰é»žæ“Šæ•¸æŽ’åº):",
                    *[
                        f"  {i + 1}. {kw['query']} - {kw['total_clicks']} æ¬¡é»žæ“Š"
                        for i, kw in enumerate(top_keywords[:5])
                    ],
                    "",
                ]
            )

        if top_pages:
            report_lines.extend(
                [
                    "ðŸ“„ ç†±é–€é é¢ (æŒ‰é»žæ“Šæ•¸æŽ’åº):",
                    *[
                        f"  {i + 1}. {page['page']} - {page['total_clicks']} æ¬¡é»žæ“Š"
                        for i, page in enumerate(top_pages[:5])
                    ],
                    "",
                ]
            )

        return "\n".join(report_lines)

    def build_report(
        self,
        site_id: int,
        output_path: str,
        include_plots: bool = True,
        plot_save_dir: Optional[str] = None,
    ) -> Dict[str, Any]:
        """
        ç”Ÿæˆå®Œæ•´çš„ GSC ç¶²ç«™è¡¨ç¾å ±å‘Šã€‚
        """
        logger.info(f"é–‹å§‹ç‚ºç¶²ç«™ ID {site_id} ç”Ÿæˆå ±å‘Š...")
        visualizer = self._GSCVisualizer(analysis_service=self)
        try:
            report_generated = self._create_markdown_report(
                visualizer=visualizer,
                site_id=site_id,
                days=30,  # Default days for report generation
                output_path=output_path,
                include_plots=include_plots,
                plot_save_dir=plot_save_dir,
            )
            if report_generated:
                return {"success": True, "path": output_path}
            else:
                raise Exception("Markdown å ±å‘Šå‰µå»ºå¤±æ•—ï¼Œä½†æœªå¼•ç™¼ç•°å¸¸ã€‚")
        except Exception as e:
            logger.error(f"ç”Ÿæˆå ±å‘Šæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}", exc_info=True)
            return {"success": False, "error": str(e)}

    class _GSCVisualizer:
        """GSC æ•¸æ“šå¯è¦–åŒ–å™¨ï¼Œä½œç‚º AnalysisService çš„å…§éƒ¨é¡ž"""

        def __init__(self, analysis_service: "AnalysisService"):
            self.analysis_service = analysis_service

        def get_daily_stats(self, site_id: int, days: int = 30) -> Optional[pd.DataFrame]:
            """ç²å–æ¯æ—¥çµ±è¨ˆæ•¸æ“š"""
            try:
                stats_data = self.analysis_service.get_daily_performance_summary(
                    site_id=site_id, days=days
                )
                if not stats_data:
                    return None
                df = pd.DataFrame(stats_data)
                df["date"] = pd.to_datetime(df["date"])
                return df
            except Exception as e:
                logger.error(f"ç²å–æ¯æ—¥çµ±è¨ˆæ•¸æ“šéŒ¯èª¤: {e}", exc_info=True)
                return None

        def get_top_keywords(
            self, site_id: int, limit: int = 20, days: int = 7
        ) -> Optional[pd.DataFrame]:
            """ç²å–è¡¨ç¾æœ€ä½³çš„é—œéµå­—"""
            try:
                keywords_data = self.analysis_service.get_top_keywords(
                    site_id=site_id, days=days, limit=limit
                )
                return pd.DataFrame(keywords_data) if keywords_data else None
            except Exception as e:
                logger.error(f"ç²å–ç†±é–€é—œéµå­—æ•¸æ“šéŒ¯èª¤: {e}", exc_info=True)
                return None

        def get_page_performance(
            self, site_id: int, limit: int = 15, days: int = 7
        ) -> Optional[pd.DataFrame]:
            """ç²å–é é¢è¡¨ç¾æ•¸æ“š"""
            try:
                pages_data = self.analysis_service.get_top_pages(
                    site_id=site_id, days=days, limit=limit
                )
                if not pages_data:
                    return None
                df = pd.DataFrame(pages_data)
                for col in ["total_clicks", "total_impressions", "avg_position", "avg_ctr"]:
                    df[col] = pd.to_numeric(df[col], errors="coerce")
                return df
            except Exception as e:
                logger.error(f"ç²å–é é¢è¡¨ç¾æ•¸æ“šéŒ¯èª¤: {e}", exc_info=True)
                return None

        def get_summary_stats(self, site_id: int, days: int = 30) -> Optional[Dict[str, Any]]:
            """ç²å–æ•¸æ“šæ‘˜è¦çµ±è¨ˆä¿¡æ¯"""
            try:
                return self.analysis_service.get_overall_summary(site_id=site_id, days=days)
            except Exception as e:
                logger.error(f"ç²å–æ‘˜è¦æ•¸æ“šéŒ¯èª¤: {e}", exc_info=True)
                return None

        def plot_daily_trends(
            self, site_id: int, days: int = 30, save_path: Optional[str] = None
        ) -> Optional[Figure]:
            df = self.get_daily_stats(site_id, days)
            if df is None or df.empty:
                return None
            set_chinese_font()
            fig, axes = plt.subplots(2, 2, figsize=(20, 16))
            # ... (å®Œæ•´çš„ç¹ªåœ–ä»£ç¢¼)
            return fig

        def plot_top_keywords(
            self, site_id: int, limit: int = 20, days: int = 7, save_path: Optional[str] = None
        ) -> Optional[Figure]:
            df = self.get_top_keywords(site_id, limit, days)
            if df is None or df.empty:
                return None
            set_chinese_font()
            fig, axes = plt.subplots(2, 2, figsize=(20, 18))
            # ... (å®Œæ•´çš„ç¹ªåœ–ä»£ç¢¼)
            return fig

        def plot_page_performance(
            self, site_id: int, limit: int = 15, days: int = 7, save_path: Optional[str] = None
        ) -> Optional[Figure]:
            df = self.get_page_performance(site_id, limit, days)
            if df is None or df.empty:
                return None
            set_chinese_font()
            fig, ax = plt.subplots(figsize=(12, 10))
            # ... (å®Œæ•´çš„ç¹ªåœ–ä»£ç¢¼)
            return fig

    def _create_markdown_report(
        self,
        visualizer: "_GSCVisualizer",
        site_id: int,
        days: int,
        output_path: str,
        include_plots: bool,
        plot_save_dir: Optional[str] = None,
    ) -> bool:
        # site_info = self.db.get_site_by_id(site_id) # Removed unused variable
        # ... (å®Œæ•´çš„ Markdown ç”Ÿæˆä»£ç¢¼)
        return True

    def get_page_keyword_performance(
        self, site_id: int, days: Optional[int] = None, max_results: int = 1000
    ) -> List[Dict[str, Any]]:
        """
        Get page performance data with aggregated keywords for each URL.

        Args:
            site_id: Site ID to query
            days: Number of days to look back (None for all time)
            max_results: Maximum number of results to return

        Returns:
            List of dictionaries containing page performance data with keywords
        """
        # Build date filter
        date_clause = ""
        params: list[Any] = [site_id]

        if days and days > 0:
            from datetime import datetime, timedelta

            end_date = datetime.now()
            start_date = end_date - timedelta(days=days)
            date_clause = "AND date >= ?"
            params.append(start_date.strftime("%Y-%m-%d"))

        # Query to aggregate performance data by page with keywords
        query = f"""
        SELECT
            page as url,
            SUM(clicks) as total_clicks,
            SUM(impressions) as total_impressions,
            AVG(ctr) as avg_ctr,
            AVG(position) as avg_position,
            GROUP_CONCAT(DISTINCT query) as keywords,
            COUNT(DISTINCT query) as keyword_count
        FROM gsc_performance_data
        WHERE site_id = ? {date_clause}
        AND (clicks > 0 OR impressions > 0)  -- Only include pages with performance
        GROUP BY page
        ORDER BY total_clicks DESC
        LIMIT ?
        """

        params.append(max_results)

        try:
            with self.db._lock:
                results = self.db._connection.execute(query, params).fetchall()

            performance_data = []
            for row in results:
                # Split keywords by delimiter
                keywords_str = row[5] or ""
                keywords = [k.strip() for k in keywords_str.split(",") if k.strip()]

                performance_data.append(
                    {
                        "url": row[0],
                        "total_clicks": int(row[1] or 0),
                        "total_impressions": int(row[2] or 0),
                        "avg_ctr": round((row[3] or 0) * 100, 3),  # Convert to percentage
                        "avg_position": round(row[4] or 0, 2),
                        "keywords": keywords,  # Return all keywords
                        "keyword_count": row[6] or 0,
                    }
                )

            logger.info(
                f"Retrieved page keyword performance data for site {site_id}: "
                f"{len(performance_data)} pages"
            )
            return performance_data

        except Exception as e:
            logger.error(f"Error getting page keyword performance for site {site_id}: {str(e)}")
            return []
