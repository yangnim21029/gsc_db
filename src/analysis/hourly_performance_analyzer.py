#!/usr/bin/env python3
"""
GSC æ¯å°æ™‚è¡¨ç¾åˆ†æå·¥å…·
å°ˆé–€ç”¨æ–¼åˆ†ææœç´¢æµé‡çš„æ™‚æ®µåˆ†ä½ˆå’Œè¡¨ç¾è¶¨å‹¢
é‡æ§‹ç‚ºå¯èª¿ç”¨å‡½æ•¸ï¼Œæ”¯æŒ CLI æ•´åˆ
"""

import sqlite3
import matplotlib.pyplot as plt
import pandas as pd
import argparse
from datetime import datetime, timedelta
import os
import seaborn as sns
from pathlib import Path
from typing import Optional, Dict, Any, List
import logging
import warnings

# å°ˆæ¡ˆæ¨¡çµ„å°å…¥
from .. import config

# è¨­ç½®æ—¥èªŒ
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# å®Œå…¨æŠ‘åˆ¶æ‰€æœ‰ matplotlib ç›¸é—œè­¦å‘Š
warnings.filterwarnings('ignore', category=UserWarning, module='matplotlib')
warnings.filterwarnings('ignore', category=UserWarning, module='matplotlib.font_manager')
warnings.filterwarnings('ignore', category=UserWarning, module='matplotlib.backends')
warnings.filterwarnings('ignore', category=RuntimeWarning, module='matplotlib')
warnings.filterwarnings('ignore', category=UserWarning, module='matplotlib.text')
warnings.filterwarnings('ignore', category=UserWarning, module='matplotlib.rcsetup')
warnings.filterwarnings('ignore', category=UserWarning, module='matplotlib.cbook')

# è¨­ç½®ç¾ä»£åŒ–è¦–è¦ºé¢¨æ ¼
plt.style.use('seaborn-v0_8-whitegrid')

# æ›´å¼·å¥çš„å­—é«”é…ç½®ï¼Œå®Œå…¨è™•ç† emoji å’Œä¸­æ–‡é¡¯ç¤ºå•é¡Œ
def configure_matplotlib_fonts():
    """é…ç½® matplotlib å­—é«”ä»¥æ”¯æŒ emoji å’Œä¸­æ–‡ï¼Œå®Œå…¨æŠ‘åˆ¶è­¦å‘Š"""
    import platform
    import matplotlib.font_manager as fm
    import matplotlib
    import matplotlib.pyplot as plt
    
    # å®Œå…¨æŠ‘åˆ¶å­—é«”ç›¸é—œè­¦å‘Š
    import warnings
    warnings.filterwarnings('ignore', category=UserWarning)
    warnings.filterwarnings('ignore', category=RuntimeWarning)
    
    # æ ¹æ“šæ“ä½œç³»çµ±é¸æ“‡åˆé©çš„å­—é«”
    system = platform.system()
    
    if system == "Darwin":  # macOS
        font_list = [
            'Arial Unicode MS',  # æœ€å…¼å®¹çš„å­—é«”ï¼Œæ”¯æŒ emoji å’Œä¸­æ–‡
            'Helvetica Neue',
            'Helvetica',
            'Arial',
            'DejaVu Sans'
        ]
    elif system == "Windows":
        font_list = [
            'Arial Unicode MS',  # æœ€å…¼å®¹çš„å­—é«”
            'Segoe UI',
            'Arial',
            'DejaVu Sans'
        ]
    else:  # Linux and others
        font_list = [
            'DejaVu Sans',  # Linux æœ€å¯é çš„å­—é«”
            'Liberation Sans',
            'Arial',
            'Helvetica'
        ]
    
    # æª¢æŸ¥å­—é«”å¯ç”¨æ€§ä¸¦è¨­ç½®
    available_fonts = []
    
    for font in font_list:
        try:
            # æ›´åš´æ ¼çš„å­—é«”æª¢æŸ¥
            font_path = fm.findfont(font)
            if font_path and font_path != matplotlib.rcParams['font.sans-serif'][0]:
                available_fonts.append(font)
        except Exception:
            continue
    
    # å¦‚æœæ²’æœ‰æ‰¾åˆ°åˆé©å­—é«”ï¼Œä½¿ç”¨åŸºæœ¬å­—é«”
    if not available_fonts:
        available_fonts = ['DejaVu Sans', 'Arial', 'Helvetica']
    
    # è¨­ç½®å­—é«”åƒæ•¸
    plt.rcParams['font.sans-serif'] = available_fonts
    plt.rcParams['axes.unicode_minus'] = False
    plt.rcParams['figure.facecolor'] = 'white'
    plt.rcParams['axes.facecolor'] = '#f8f9fa'
    
    # ä½¿ç”¨æ›´å¯é çš„æ–¹æ³•è¨­ç½® unicode_minus
    plt.rc('axes', unicode_minus=False)
    
    # æ¸…é™¤å­—é«”ç·©å­˜ä»¥ç¢ºä¿æ–°é…ç½®ç”Ÿæ•ˆ
    try:
        # å˜—è©¦æ¸…é™¤å­—é«”ç·©å­˜
        if hasattr(fm.findfont, 'cache_clear'):
            fm.findfont.cache_clear()
    except Exception:
        pass
    
    # è¨­ç½®å…¨å±€è­¦å‘Šéæ¿¾
    warnings.filterwarnings('ignore', category=UserWarning, module='matplotlib')
    warnings.filterwarnings('ignore', category=UserWarning, module='matplotlib.font_manager')
    warnings.filterwarnings('ignore', category=UserWarning, module='matplotlib.backends')
    warnings.filterwarnings('ignore', category=RuntimeWarning, module='matplotlib')
    
    return True, True

# é…ç½®å­—é«”ä¸¦ç²å–æ”¯æŒç‹€æ…‹
EMOJI_SUPPORTED, CHINESE_SUPPORTED = configure_matplotlib_fonts()

# å°ˆæ¥­é…è‰²æ–¹æ¡ˆ
HOURLY_COLORS = {
    'morning': '#ffbe0b',    # æ—©æ™¨ 6-11
    'noon': '#fb5607',       # ä¸­åˆ 12-17
    'evening': '#8338ec',    # æ™šä¸Š 18-23
    'night': '#3a86ff',      # æ·±å¤œ 0-5
    'primary': '#06d6a0',
    'secondary': '#f77f00',
    'accent': '#fcbf49'
}


class HourlyAnalyzer:
    """æ¯å°æ™‚æ•¸æ“šåˆ†æå™¨"""

    def __init__(self, db_path: str = str(config.DB_PATH)):
        self.db_path = db_path or str(config.DB_PATH)

    def get_hourly_summary(self, days=7):
        """ç²å–æ¯å°æ™‚æ•¸æ“šæ‘˜è¦"""
        try:
            conn = sqlite3.connect(self.db_path)

            # ç²å–æœ€æ–°æ—¥æœŸ
            cursor = conn.execute("SELECT MAX(date) FROM hourly_rankings")
            latest_date_str = cursor.fetchone()[0]
            if not latest_date_str:
                return None

            latest_date = datetime.strptime(latest_date_str, '%Y-%m-%d').date()
            start_date = latest_date - timedelta(days=days - 1)

            query = """
            SELECT
                hour,
                COUNT(*) as total_records,
                COUNT(DISTINCT query) as unique_queries,
                COUNT(DISTINCT date) as days_active,
                SUM(clicks) as total_clicks,
                SUM(impressions) as total_impressions,
                AVG(position) as avg_position,
                AVG(ctr) as avg_ctr
            FROM hourly_rankings
            WHERE date >= ? AND date <= ?
            GROUP BY hour
            ORDER BY hour
            """

            df = pd.read_sql_query(
                query, conn, params=(
                    start_date, latest_date))
            conn.close()

            return df

        except Exception as e:
            logger.error(f"ç²å–æ¯å°æ™‚æ‘˜è¦éŒ¯èª¤: {e}")
            return None

    def get_daily_hourly_heatmap(self, days=7):
        """ç²å–æ¯æ—¥æ¯å°æ™‚ç†±åŠ›åœ–æ•¸æ“š"""
        try:
            conn = sqlite3.connect(self.db_path)

            cursor = conn.execute("SELECT MAX(date) FROM hourly_rankings")
            latest_date_str = cursor.fetchone()[0]
            if not latest_date_str:
                return None

            latest_date = datetime.strptime(latest_date_str, '%Y-%m-%d').date()
            start_date = latest_date - timedelta(days=days - 1)

            query = """
            SELECT
                date,
                hour,
                COUNT(*) as records,
                SUM(clicks) as clicks,
                SUM(impressions) as impressions,
                AVG(position) as avg_position
            FROM hourly_rankings
            WHERE date >= ? AND date <= ?
            GROUP BY date, hour
            ORDER BY date, hour
            """

            df = pd.read_sql_query(
                query, conn, params=(
                    start_date, latest_date))
            conn.close()

            return df

        except Exception as e:
            logger.error(f"ç²å–ç†±åŠ›åœ–æ•¸æ“šéŒ¯èª¤: {e}")
            return None

    def get_peak_hours_analysis(self, days=7):
        """åˆ†æé«˜å³°æ™‚æ®µ"""
        df = self.get_hourly_summary(days)
        if df is None or df.empty:
            return None

        # å®šç¾©æ™‚æ®µ
        df['time_period'] = df['hour'].apply(self._categorize_hour)

        # æŒ‰æ™‚æ®µèšåˆ
        period_stats = df.groupby('time_period').agg({
            'total_clicks': 'sum',
            'total_impressions': 'sum',
            'unique_queries': 'sum',
            'avg_position': 'mean'
        }).reset_index()

        return df, period_stats

    def _categorize_hour(self, hour):
        """å°‡å°æ™‚åˆ†é¡ç‚ºæ™‚æ®µ"""
        if 6 <= hour <= 11:
            return 'æ—©æ™¨ (6-11)'
        elif 12 <= hour <= 17:
            return 'ä¸­åˆ (12-17)'
        elif 18 <= hour <= 23:
            return 'æ™šä¸Š (18-23)'
        else:
            return 'æ·±å¤œ (0-5)'

    def plot_hourly_trends(self, days=7, save_path=None):
        """ç¹ªè£½æ¯å°æ™‚è¶¨å‹¢åœ–"""
        df = self.get_hourly_summary(days)
        if df is None or df.empty:
            logger.error("ç„¡æ³•ç²å–æ¯å°æ™‚æ•¸æ“š")
            return None

        fig = plt.figure(figsize=(16, 12), constrained_layout=True)
        gs = fig.add_gridspec(3, 2, height_ratios=[2, 2, 1])

        # ä¸»è¦è¶¨å‹¢åœ–
        ax1 = fig.add_subplot(gs[0, :])

        # é›™è»¸ï¼šé»æ“Šé‡å’Œæ›å…‰é‡
        ax1_twin = ax1.twinx()

        # é»æ“Šé‡ç·šæ¢
        ax1.plot(
            df['hour'],
            df['total_clicks'],
            color=HOURLY_COLORS['primary'],
            linewidth=4,
            marker='o',
            markersize=8,
            markerfacecolor='white',
            markeredgewidth=3,
            markeredgecolor=HOURLY_COLORS['primary'],
            label='é»æ“Šé‡')

        # æ›å…‰é‡å€åŸŸåœ–
        ax1_twin.fill_between(df['hour'], df['total_impressions'],
                              color=HOURLY_COLORS['secondary'], alpha=0.3)
        ax1_twin.plot(df['hour'], df['total_impressions'],
                      color=HOURLY_COLORS['secondary'], linewidth=2,
                      linestyle='--', label='æ›å…‰é‡')

        # ç¾åŒ–ä¸»åœ–
        ax1.set_title(f'24å°æ™‚æœç´¢è¡¨ç¾è¶¨å‹¢ (è¿‘{days}å¤©)',
                      fontsize=18, fontweight='bold', pad=20)
        ax1.set_xlabel('å°æ™‚', fontsize=12, fontweight='bold')
        ax1.set_ylabel(
            'é»æ“Šé‡',
            fontsize=12,
            color=HOURLY_COLORS['primary'],
            fontweight='bold')
        ax1_twin.set_ylabel(
            'æ›å…‰é‡',
            fontsize=12,
            color=HOURLY_COLORS['secondary'],
            fontweight='bold')

        # è¨­ç½®åˆ»åº¦
        ax1.set_xticks(range(0, 24, 2))
        ax1.grid(True, alpha=0.3)

        # æ·»åŠ åœ–ä¾‹
        lines1, labels1 = ax1.get_legend_handles_labels()
        lines2, labels2 = ax1_twin.get_legend_handles_labels()
        ax1.legend(lines1 + lines2, labels1 + labels2, loc='upper left')

        # å­åœ–1ï¼šæ¯å°æ™‚é—œéµå­—æ•¸é‡
        ax2 = fig.add_subplot(gs[1, 0])
        ax2.bar(df['hour'], df['unique_queries'],
                color=HOURLY_COLORS['accent'], alpha=0.8, edgecolor='white', linewidth=1)
        ax2.set_title('æ¯å°æ™‚é—œéµå­—æ•¸é‡', fontsize=14, fontweight='bold')
        ax2.set_xlabel('å°æ™‚')
        ax2.set_ylabel('é—œéµå­—æ•¸é‡')
        ax2.set_xticks(range(0, 24, 2))
        ax2.grid(True, alpha=0.3)

        # å­åœ–2ï¼šæ¯å°æ™‚å¹³å‡æ’å
        ax3 = fig.add_subplot(gs[1, 1])
        ax3.plot(df['hour'], df['avg_position'],
                 color='#e74c3c', linewidth=3, marker='s', markersize=6)
        ax3.fill_between(df['hour'], df['avg_position'],
                         color='#e74c3c', alpha=0.3)
        ax3.set_title('æ¯å°æ™‚å¹³å‡æ’å', fontsize=14, fontweight='bold')
        ax3.set_xlabel('å°æ™‚')
        ax3.set_ylabel('å¹³å‡æ’å')
        ax3.set_xticks(range(0, 24, 2))
        ax3.invert_yaxis()
        ax3.grid(True, alpha=0.3)

        # çµ±è¨ˆæ‘˜è¦
        ax4 = fig.add_subplot(gs[2, :])
        ax4.axis('off')

        # è¨ˆç®—çµ±è¨ˆæ•¸æ“š
        peak_hour = df.loc[df['total_clicks'].idxmax()]
        low_hour = df.loc[df['total_clicks'].idxmin()]
        total_clicks = df['total_clicks'].sum()
        total_impressions = df['total_impressions'].sum()

        # ä½¿ç”¨ç´”æ–‡å­—æ ¼å¼ï¼Œé¿å… emoji å­—é«”å•é¡Œ
        stats_text = f"""
        çµ±è¨ˆæ‘˜è¦ (è¿‘{days}å¤©)
        
        [é«˜å³°] é«˜å³°æ™‚æ®µ: {peak_hour['hour']}é» ({peak_hour['total_clicks']:,}æ¬¡é»æ“Š)
        [ä½è°·] ä½è°·æ™‚æ®µ: {low_hour['hour']}é» ({low_hour['total_clicks']:,}æ¬¡é»æ“Š)
        [è¶¨å‹¢] é»æ“Šç¸½é‡: {total_clicks:,}
        [æ›å…‰] æ›å…‰ç¸½é‡: {total_impressions:,}
        [é—œéµå­—] é—œéµå­—ç¸½æ•¸: {df['unique_queries'].sum():,}
        """

        ax4.text(0.05, 0.5, stats_text, transform=ax4.transAxes,
                 fontsize=12, verticalalignment='center',
                 bbox=dict(boxstyle="round,pad=0.5", facecolor='lightgray', alpha=0.8))

        # Using constrained_layout instead of tight_layout for better compatibility

        if save_path:
            if not save_path.endswith(('.png', '.jpg', '.jpeg', '.pdf')):
                save_path += '.png'

            save_path_obj = Path(save_path)
            if not save_path_obj.parent.exists():
                save_path_obj.parent.mkdir(parents=True, exist_ok=True)
            plt.savefig(save_path_obj, dpi=300, bbox_inches='tight',
                        facecolor='white', edgecolor='none')
            logger.info(f"ğŸ“ˆ æ¯å°æ™‚è¶¨å‹¢åœ–å·²ä¿å­˜åˆ°: {save_path}")
            return save_path
        else:
            plt.show()
            return None

    def plot_heatmap(self, days=7, save_path=None):
        """ç¹ªè£½æ¯æ—¥æ¯å°æ™‚ç†±åŠ›åœ–"""
        df = self.get_daily_hourly_heatmap(days)
        if df is None or df.empty:
            logger.error("ç„¡æ³•ç²å–ç†±åŠ›åœ–æ•¸æ“š")
            return None

        # å‰µå»ºé€è¦–è¡¨
        pivot_clicks = df.pivot(
            index='date',
            columns='hour',
            values='clicks').fillna(0)
        pivot_impressions = df.pivot(
            index='date',
            columns='hour',
            values='impressions').fillna(0)

        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(16, 10), constrained_layout=True)

        # é»æ“Šé‡ç†±åŠ›åœ–
        sns.heatmap(pivot_clicks, annot=True, fmt='.0f', cmap='YlOrRd',
                    ax=ax1, cbar_kws={'label': 'é»æ“Šé‡'})
        ax1.set_title('æ¯æ—¥æ¯å°æ™‚é»æ“Šé‡åˆ†å¸ƒ', fontsize=16, fontweight='bold', pad=20)
        ax1.set_xlabel('å°æ™‚', fontsize=12)
        ax1.set_ylabel('æ—¥æœŸ', fontsize=12)

        # æ›å…‰é‡ç†±åŠ›åœ–
        sns.heatmap(pivot_impressions, annot=True, fmt='.0f', cmap='Blues',
                    ax=ax2, cbar_kws={'label': 'æ›å…‰é‡'})
        ax2.set_title('æ¯æ—¥æ¯å°æ™‚æ›å…‰é‡åˆ†å¸ƒ', fontsize=16, fontweight='bold', pad=20)
        ax2.set_xlabel('å°æ™‚', fontsize=12)
        ax2.set_ylabel('æ—¥æœŸ', fontsize=12)

        # Using constrained_layout instead of tight_layout for better compatibility

        if save_path:
            if not save_path.endswith(('.png', '.jpg', '.jpeg', '.pdf')):
                save_path += '.png'

            save_path_obj = Path(save_path)
            if not save_path_obj.parent.exists():
                save_path_obj.parent.mkdir(parents=True, exist_ok=True)
            plt.savefig(save_path_obj, dpi=300, bbox_inches='tight',
                        facecolor='white', edgecolor='none')
            logger.info(f"ğŸ”¥ ç†±åŠ›åœ–å·²ä¿å­˜åˆ°: {save_path}")
            return save_path
        else:
            plt.show()
            return None

    def plot_peak_analysis(self, days=7, save_path=None):
        """ç¹ªè£½é«˜å³°æ™‚æ®µåˆ†æ"""
        hourly_df, period_df = self.get_peak_hours_analysis(days)
        if hourly_df is None or period_df is None:
            logger.error("ç„¡æ³•ç²å–é«˜å³°åˆ†ææ•¸æ“š")
            return None

        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12), constrained_layout=True)

        # æ™‚æ®µé»æ“Šé‡åˆ†å¸ƒ
        colors = [HOURLY_COLORS['night'], HOURLY_COLORS['morning'],
                  HOURLY_COLORS['noon'], HOURLY_COLORS['evening']]

        wedges, texts, autotexts = ax1.pie(period_df['total_clicks'],
                                           labels=period_df['time_period'],
                                           colors=colors, autopct='%1.1f%%',
                                           startangle=90)
        ax1.set_title('å„æ™‚æ®µé»æ“Šé‡åˆ†å¸ƒ', fontsize=14, fontweight='bold')

        # æ™‚æ®µæ›å…‰é‡å°æ¯”
        bars = ax2.bar(range(len(period_df)), period_df['total_impressions'],
                       color=colors, alpha=0.8, edgecolor='white', linewidth=2)
        ax2.set_title('å„æ™‚æ®µæ›å…‰é‡å°æ¯”', fontsize=14, fontweight='bold')
        ax2.set_xticks(range(len(period_df)))
        ax2.set_xticklabels(period_df['time_period'], rotation=45)
        ax2.set_ylabel('æ›å…‰é‡')

        # æ·»åŠ æ•¸å€¼æ¨™ç±¤
        for bar in bars:
            height = bar.get_height()
            ax2.annotate(f'{int(height):,}',
                         xy=(bar.get_x() + bar.get_width() / 2, height),
                         xytext=(0, 3), textcoords="offset points",
                         ha='center', va='bottom', fontweight='bold')

        # æ¯å°æ™‚é»æ“Šè¶¨å‹¢ï¼ˆå½©è™¹åœ–ï¼‰
        for i, hour in enumerate(hourly_df['hour']):
            color = (colors[0] if hour < 6 else
                     colors[1] if hour < 12 else
                     colors[2] if hour < 18 else
                     colors[3])
            ax3.bar(hour, hourly_df.iloc[i]['total_clicks'],
                    color=color, alpha=0.8, width=0.8)

        ax3.set_title('24å°æ™‚é»æ“Šé‡åˆ†å¸ƒ', fontsize=14, fontweight='bold')
        ax3.set_xlabel('å°æ™‚')
        ax3.set_ylabel('é»æ“Šé‡')
        ax3.set_xticks(range(0, 24, 2))

        # æ’åè¡¨ç¾
        ax4.plot(hourly_df['hour'], hourly_df['avg_position'],
                 color='#e74c3c', linewidth=3, marker='o', markersize=5)
        ax4.fill_between(hourly_df['hour'], hourly_df['avg_position'],
                         color='#e74c3c', alpha=0.3)
        ax4.set_title('24å°æ™‚å¹³å‡æ’åè®ŠåŒ–', fontsize=14, fontweight='bold')
        ax4.set_xlabel('å°æ™‚')
        ax4.set_ylabel('å¹³å‡æ’å')
        ax4.set_xticks(range(0, 24, 2))
        ax4.invert_yaxis()

        # Using constrained_layout instead of tight_layout for better compatibility

        if save_path:
            if not save_path.endswith(('.png', '.jpg', '.jpeg', '.pdf')):
                save_path += '.png'

            save_path_obj = Path(save_path)
            if not save_path_obj.parent.exists():
                save_path_obj.parent.mkdir(parents=True, exist_ok=True)
            plt.savefig(save_path_obj, dpi=300, bbox_inches='tight',
                        facecolor='white', edgecolor='none')
            logger.info(f"â° é«˜å³°åˆ†æåœ–å·²ä¿å­˜åˆ°: {save_path}")
            return save_path
        else:
            plt.show()
            return None

    def generate_hourly_report(self, days=7, output_path="hourly_report.md"):
        """ç”Ÿæˆæ¯å°æ™‚æ•¸æ“šå ±å‘Š"""
        try:
            # åŸºæœ¬çµ±è¨ˆ
            conn = sqlite3.connect(self.db_path)
            cursor = conn.execute("SELECT COUNT(*) FROM hourly_rankings")
            total_records = cursor.fetchone()[0]

            cursor = conn.execute(
                "SELECT COUNT(DISTINCT date) FROM hourly_rankings")
            total_days = cursor.fetchone()[0]

            cursor = conn.execute(
                "SELECT COUNT(DISTINCT query) FROM hourly_rankings")
            unique_queries = cursor.fetchone()[0]

            cursor = conn.execute(
                "SELECT MIN(date), MAX(date) FROM hourly_rankings")
            date_range = cursor.fetchone()

            # æ¯å°æ™‚æ‘˜è¦
            df = self.get_hourly_summary(days)
            
            # ç”Ÿæˆå ±å‘Šå…§å®¹
            report_content = f"""# GSC æ¯å°æ™‚æ•¸æ“šåˆ†æå ±å‘Š

## ğŸ“Š æ•¸æ“šæ¦‚è¦½

- **ç¸½è¨˜éŒ„æ•¸**: {total_records:,}
- **è¦†è“‹å¤©æ•¸**: {total_days}
- **ç¨ç‰¹é—œéµå­—**: {unique_queries:,}
- **æ—¥æœŸç¯„åœ**: {date_range[0]} è‡³ {date_range[1]}

## ğŸ¯ åˆ†ææœŸé–“

æœ¬å ±å‘Šåˆ†ææœ€è¿‘ **{days} å¤©** çš„æ¯å°æ™‚è¡¨ç¾ã€‚

## ğŸ“ˆ æ¯å°æ™‚è¡¨ç¾æ‘˜è¦

| å°æ™‚ | é»æ“Šæ•¸ | å±•ç¤ºæ•¸ | é—œéµå­—æ•¸ | å¹³å‡æ’å | CTR |
|------|--------|--------|----------|----------|-----|
"""

            if df is not None and not df.empty:
                for _, row in df.iterrows():
                    hour_val = row['hour']
                    try:
                        hour_val = int(round(float(hour_val)))
                    except Exception:
                        hour_val = 0
                    report_content += f"| {hour_val:02d}:00 | {int(row['total_clicks']):,} | {int(row['total_impressions']):,} | {int(row['unique_queries']):,} | {row['avg_position']:.1f} | {row['avg_ctr']:.2%} |\n"
                
                # æ·»åŠ çµ±è¨ˆæ‘˜è¦
                peak_hour = df.loc[df['total_clicks'].idxmax()]
                low_hour = df.loc[df['total_clicks'].idxmin()]
                
                report_content += f"""

## ğŸ† é«˜å³°æ™‚æ®µåˆ†æ

- **é«˜å³°æ™‚æ®µ**: {peak_hour['hour']:02d}:00 ({peak_hour['total_clicks']:,}æ¬¡é»æ“Š)
- **ä½è°·æ™‚æ®µ**: {low_hour['hour']:02d}:00 ({low_hour['total_clicks']:,}æ¬¡é»æ“Š)
- **é»æ“Šç¸½é‡**: {df['total_clicks'].sum():,}
- **æ›å…‰ç¸½é‡**: {df['total_impressions'].sum():,}
- **é—œéµå­—ç¸½æ•¸**: {df['unique_queries'].sum():,}
"""
            else:
                report_content += "| - | ç„¡æ•¸æ“š | - | - | - | - |\n"

            report_content += f"""

## ğŸ“… å ±å‘Šç”Ÿæˆæ™‚é–“

{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

---

*æ­¤å ±å‘Šç”± GSC æ¯å°æ™‚æ•¸æ“šåˆ†æå·¥å…·è‡ªå‹•ç”Ÿæˆ*
"""

            # ä¿å­˜å ±å‘Š
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(report_content)

            conn.close()
            logger.info(f"ğŸ“„ æ¯å°æ™‚å ±å‘Šå·²ä¿å­˜åˆ°: {output_path}")
            return output_path

        except Exception as e:
            logger.error(f"ç”Ÿæˆæ¯å°æ™‚å ±å‘Šå¤±æ•—: {e}")
            return None


def _generate_hourly_trends_plot(analyzer: HourlyAnalyzer, days: int = 7, save_path: Optional[str] = None) -> Optional[str]:
    """ç”Ÿæˆæ¯å°æ™‚è¶¨å‹¢åœ–"""
    try:
        return analyzer.plot_hourly_trends(days=days, save_path=save_path)
    except Exception as e:
        logger.error(f"ç”Ÿæˆæ¯å°æ™‚è¶¨å‹¢åœ–å¤±æ•—: {e}")
        return None


def _generate_hourly_heatmap(analyzer: HourlyAnalyzer, days: int = 7, save_path: Optional[str] = None) -> Optional[str]:
    """ç”Ÿæˆæ¯å°æ™‚ç†±åŠ›åœ–"""
    try:
        return analyzer.plot_heatmap(days=days, save_path=save_path)
    except Exception as e:
        logger.error(f"ç”Ÿæˆæ¯å°æ™‚ç†±åŠ›åœ–å¤±æ•—: {e}")
        return None


def _generate_peak_analysis_plot(analyzer: HourlyAnalyzer, days: int = 7, save_path: Optional[str] = None) -> Optional[str]:
    """ç”Ÿæˆé«˜å³°åˆ†æåœ–"""
    try:
        return analyzer.plot_peak_analysis(days=days, save_path=save_path)
    except Exception as e:
        logger.error(f"ç”Ÿæˆé«˜å³°åˆ†æåœ–å¤±æ•—: {e}")
        return None

def _generate_hourly_report(analyzer: HourlyAnalyzer, days: int = 7, save_path: Optional[str] = None) -> Optional[str]:
    """ç”Ÿæˆæ¯å°æ™‚å ±å‘Š"""
    try:
        # The analyzer method expects output_path, so we pass save_path to it.
        if save_path is None:
            return None
        return analyzer.generate_hourly_report(days=days, output_path=save_path)
    except Exception as e:
        logger.error(f"ç”Ÿæˆæ¯å°æ™‚å ±å‘Šå¤±æ•—: {e}")
        return None

# åˆ†æä»»å‹™è¨»å†Šè¡¨ï¼Œæ–¹ä¾¿æ“´å±•
ANALYSIS_REGISTRY = {
    'trends': {
        'function': _generate_hourly_trends_plot,
        'type': 'plot',
        'filename': 'hourly_trends.png'
    },
    'heatmap': {
        'function': _generate_hourly_heatmap,
        'type': 'plot',
        'filename': 'hourly_heatmap.png'
    },
    'peaks': {
        'function': _generate_peak_analysis_plot,
        'type': 'plot',
        'filename': 'peak_analysis.png'
    },
    'report': {
        'function': _generate_hourly_report,
        'type': 'report',
        'filename': 'hourly_report.md'
    }
}

def _fetch_hourly_data_gemini(conn, days: int, site_url: Optional[str] = None) -> pd.DataFrame:
    """
    Fetches and aggregates performance data by hour from the database (Gemini style).
    This query assumes the 'date' column is a format that SQLite's strftime can parse (e.g., 'YYYY-MM-DD HH:MM:SS').
    """
    end_date = datetime.now().date()
    start_date = end_date - timedelta(days=days)
    query = """
    SELECT
        CAST(strftime('%H', date) AS INTEGER) as hour,
        SUM(clicks) as total_clicks,
        SUM(impressions) as total_impressions
    FROM gsc_data
    WHERE date(date) >= ? AND date(date) <= ?
    """
    params = [str(start_date), str(end_date)]
    if site_url:
        query += " AND site_url = ?"
        params.append(site_url)
    query += " GROUP BY hour ORDER BY hour ASC"
    return pd.read_sql_query(query, conn, params=params)


def _generate_hourly_plot_gemini(df: pd.DataFrame, output_dir: Path, filename_prefix: str) -> Optional[Path]:
    """Generates and saves a plot of clicks by hour of the day (Gemini style)."""
    if df.empty:
        return None
    plt.style.use('seaborn-v0_8-whitegrid')
    plt.figure(figsize=(14, 7), constrained_layout=True)
    sns.barplot(x='hour', y='total_clicks', data=df, palette='plasma', hue='hour', dodge=False, legend=False)
    plt.title(f'{filename_prefix} - Clicks by Hour of Day (UTC)', fontsize=16, pad=20)
    plt.xlabel('Hour of Day', fontsize=12)
    plt.ylabel('Total Clicks', fontsize=12)
    plt.xticks(range(0, 24))
    # Using constrained_layout instead of tight_layout for better compatibility
    output_dir.mkdir(parents=True, exist_ok=True)
    plot_path = output_dir / f"{filename_prefix}_Hourly_Trends.png"
    plt.savefig(plot_path)
    plt.close()
    return plot_path


def run_hourly_analysis(
    analysis_type: str = "trends",
    days: int = 7,
    output_path: Optional[str] = None,
    include_plots: bool = True,
    plot_save_dir: Optional[str] = None,
    db_path: str = str(config.DB_PATH)
) -> Dict[str, Any]:
    """
    é‹è¡Œæ¯å°æ™‚æ•¸æ“šåˆ†æ
    
    Args:
        analysis_type: åˆ†æé¡å‹ ('trends', 'heatmap', 'peaks', 'report', 'all')
        days: åˆ†æå¤©æ•¸
        output_path: å ±å‘Šè¼¸å‡ºè·¯å¾‘
        include_plots: æ˜¯å¦åŒ…å«åœ–è¡¨
        plot_save_dir: åœ–è¡¨ä¿å­˜ç›®éŒ„
        db_path: æ•¸æ“šåº«è·¯å¾‘
    
    Returns:
        åŒ…å«åˆ†æçµæœçš„å­—å…¸
    """
    result = {
        'success': False,
        'analysis_type': analysis_type,
        'plots_generated': [],
        'report_path': None,
        'errors': []
    }
    
    try:
        logger.info(f"é–‹å§‹æ¯å°æ™‚æ•¸æ“šåˆ†æï¼Œé¡å‹: {analysis_type}ï¼Œå¤©æ•¸: {days}")
        
        # åˆå§‹åŒ–åˆ†æå™¨
        analyzer = HourlyAnalyzer(db_path)
        
        # æª¢æŸ¥æ•¸æ“šåº«æ˜¯å¦å­˜åœ¨
        if not Path(db_path).exists():
            error_msg = f"æ•¸æ“šåº«æ–‡ä»¶ä¸å­˜åœ¨: {db_path}"
            logger.error(error_msg)
            result['errors'].append(error_msg)
            return result
        
        # æª¢æŸ¥æ¯å°æ™‚æ•¸æ“šè¡¨æ˜¯å¦å­˜åœ¨
        try:
            conn = sqlite3.connect(db_path)
            cursor = conn.execute("SELECT name FROM sqlite_master WHERE type='table' AND name='hourly_rankings'")
            if not cursor.fetchone():
                error_msg = "æ¯å°æ™‚æ•¸æ“šè¡¨ 'hourly_rankings' ä¸å­˜åœ¨"
                logger.error(error_msg)
                result['errors'].append(error_msg)
                conn.close()
                return result
            conn.close()
        except Exception as e:
            error_msg = f"æª¢æŸ¥æ•¸æ“šåº«çµæ§‹å¤±æ•—: {e}"
            logger.error(error_msg)
            result['errors'].append(error_msg)
            return result
        
        # ç¢ºå®šè¦é‹è¡Œçš„åˆ†æä»»å‹™
        analyses_to_run = []
        if analysis_type == 'all':
            analyses_to_run = list(ANALYSIS_REGISTRY.keys())
        elif analysis_type in ANALYSIS_REGISTRY:
            analyses_to_run = [analysis_type]
        else:
            error_msg = f"ç„¡æ•ˆçš„åˆ†æé¡å‹: {analysis_type}. å¯ç”¨é¡å‹: {list(ANALYSIS_REGISTRY.keys()) + ['all']}"
            logger.error(error_msg)
            result['errors'].append(error_msg)
            return result

        # åŸ·è¡Œåˆ†æä»»å‹™
        for name in analyses_to_run:
            task = ANALYSIS_REGISTRY[name]
            
            if task['type'] == 'plot' and include_plots:
                plot_dir = Path(plot_save_dir) if plot_save_dir else config.ASSETS_DIR
                plot_dir.mkdir(exist_ok=True)
                save_path = plot_dir / task['filename']
                
                if task['function'](analyzer, days, str(save_path)):
                    result['plots_generated'].append(str(save_path))

            elif task['type'] == 'report':
                report_save_path = output_path
                if not report_save_path:
                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                    report_save_path = config.REPORTS_DIR / f"hourly_report_{timestamp}.md"
                
                if task['function'](analyzer, days, str(report_save_path)):
                    result['report_path'] = str(report_save_path)
        
        result['success'] = True
        logger.info(f"æ¯å°æ™‚åˆ†æå®Œæˆ: {analysis_type}")
        
        # æ·»åŠ æ•¸æ“šæ‘˜è¦
        df = analyzer.get_hourly_summary(days)
        if df is not None and not df.empty:
            result['summary'] = {
                'total_clicks': int(df['total_clicks'].sum()),
                'total_impressions': int(df['total_impressions'].sum()),
                'unique_queries': int(df['unique_queries'].sum()),
                'peak_hour': int(df.loc[df['total_clicks'].idxmax()]['hour']),
                'low_hour': int(df.loc[df['total_clicks'].idxmin()]['hour'])
            }
        
        return result
        
    except Exception as e:
        error_msg = f"æ¯å°æ™‚åˆ†ææ™‚ç™¼ç”ŸéŒ¯èª¤: {e}"
        logger.error(error_msg)
        result['errors'].append(error_msg)
        return result


def run_hourly_analysis_gemini(site_url: Optional[str] = None, days: int = 30):
    print(f"Running hourly analysis for site: {site_url or 'All Sites'} for the last {days} days...")
    from services.database import Database
    conn = Database().get_connection()
    try:
        hourly_data = _fetch_hourly_data_gemini(conn, days, site_url)
        if hourly_data.empty:
            print("âš ï¸ No hourly data found for the specified period.")
            return
        assets_dir = Path("assets")
        timestamp = datetime.now().strftime("%Y_%B")
        site_name = Path(site_url).stem if site_url else "Overall"
        filename_prefix = f"{timestamp}_{site_name}"
        plot_path = _generate_hourly_plot_gemini(hourly_data, assets_dir, filename_prefix)
        print(f"âœ… Hourly trends plot saved to: {plot_path}")
        peak_hour_data = hourly_data.loc[hourly_data['total_clicks'].idxmax()]
        print(f"ğŸ“ˆ Peak Performance Hour: {int(peak_hour_data['hour']):02d}:00 UTC with {int(peak_hour_data['total_clicks']):,} clicks.")
    except Exception as e:
        print(f"âŒ An error occurred during hourly analysis: {e}")
    finally:
        if conn:
            conn.close()


def main():
    """ä¸»å‡½æ•¸ - ç”¨æ–¼ç›´æ¥é‹è¡Œè…³æœ¬"""
    parser = argparse.ArgumentParser(description='GSC æ¯å°æ™‚æ•¸æ“šåˆ†æå·¥å…·')
    parser.add_argument(
        '--type',
        choices=[
            'trends',
            'heatmap',
            'peaks',
            'report',
            'all'],
        default='trends',
        help='åˆ†æé¡å‹')
    parser.add_argument('--days', type=int, default=7, help='åˆ†æå¤©æ•¸')
    parser.add_argument('--output', help='å ±å‘Šè¼¸å‡ºè·¯å¾‘')
    parser.add_argument('--no-plots', action='store_true', help='ä¸ç”Ÿæˆåœ–è¡¨')
    parser.add_argument('--plot-dir', default='assets', help='åœ–è¡¨ä¿å­˜ç›®éŒ„')
    parser.add_argument('--db', default='gsc_data.db', help='æ•¸æ“šåº«æ–‡ä»¶è·¯å¾‘')
    
    args = parser.parse_args()
    
    # èª¿ç”¨ä¸»å‡½æ•¸
    result = run_hourly_analysis(
        analysis_type=args.type,
        days=args.days,
        output_path=args.output,
        include_plots=not args.no_plots,
        plot_save_dir=args.plot_dir,
        db_path=args.db
    )
    
    if result['success']:
        print(f"âœ… æ¯å°æ™‚åˆ†ææˆåŠŸ: {result['analysis_type']}")
        if result['plots_generated']:
            print(f"ğŸ“Š ç”Ÿæˆçš„åœ–è¡¨: {', '.join(result['plots_generated'])}")
        if result['report_path']:
            print(f"ğŸ“„ å ±å‘Šè·¯å¾‘: {result['report_path']}")
        if 'summary' in result:
            summary = result['summary']
            print(f"ğŸ“ˆ æ•¸æ“šæ‘˜è¦: {summary['total_clicks']:,} é»æ“Š, {summary['total_impressions']:,} æ›å…‰")
            print(f"â° é«˜å³°æ™‚æ®µ: {summary['peak_hour']}:00, ä½è°·æ™‚æ®µ: {summary['low_hour']}:00")
    else:
        print("âŒ æ¯å°æ™‚åˆ†æå¤±æ•—")
        for error in result['errors']:
            print(f"  - {error}")
        return 1
    
    return 0


if __name__ == "__main__":
    exit(main())
