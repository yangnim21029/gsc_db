#!/usr/bin/env python3
"""
GSC æ¯å°æ™‚è¡¨ç¾åˆ†æå·¥å…·
å°ˆé–€ç”¨æ–¼åˆ†ææœç´¢æµé‡çš„æ™‚æ®µåˆ†ä½ˆå’Œè¡¨ç¾è¶¨å‹¢
é‡æ§‹ç‚ºå¯èª¿ç”¨å‡½æ•¸ï¼Œæ”¯æŒ CLI æ•´åˆ
"""

import argparse
import logging
import warnings
from datetime import datetime, timedelta
from pathlib import Path
from typing import Any, Callable, Dict, Optional

import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns

# å°ˆæ¡ˆæ¨¡çµ„å°å…¥
from .. import config
from ..services.database import Database

# è¨­ç½®æ—¥èªŒ
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# å®Œå…¨æŠ‘åˆ¶æ‰€æœ‰ matplotlib ç›¸é—œè­¦å‘Š
warnings.filterwarnings("ignore", category=UserWarning, module="matplotlib")
warnings.filterwarnings("ignore", category=UserWarning, module="matplotlib.font_manager")
warnings.filterwarnings("ignore", category=UserWarning, module="matplotlib.backends")
warnings.filterwarnings("ignore", category=RuntimeWarning, module="matplotlib")
warnings.filterwarnings("ignore", category=UserWarning, module="matplotlib.text")
warnings.filterwarnings("ignore", category=UserWarning, module="matplotlib.rcsetup")
warnings.filterwarnings("ignore", category=UserWarning, module="matplotlib.cbook")

# è¨­ç½®ç¾ä»£åŒ–è¦–è¦ºé¢¨æ ¼
plt.style.use("seaborn-v0_8-whitegrid")


# æ›´å¼·å¥çš„å­—é«”é…ç½®ï¼Œå®Œå…¨è™•ç† emoji å’Œä¸­æ–‡é¡¯ç¤ºå•é¡Œ
def configure_matplotlib_fonts():
    """é…ç½® matplotlib å­—é«”ä»¥æ”¯æŒ emoji å’Œä¸­æ–‡ï¼Œå®Œå…¨æŠ‘åˆ¶è­¦å‘Š"""
    import platform

    # å®Œå…¨æŠ‘åˆ¶å­—é«”ç›¸é—œè­¦å‘Š
    import warnings

    import matplotlib
    import matplotlib.font_manager as fm
    import matplotlib.pyplot as plt

    warnings.filterwarnings("ignore", category=UserWarning)
    warnings.filterwarnings("ignore", category=RuntimeWarning)

    # æ ¹æ“šæ“ä½œç³»çµ±é¸æ“‡åˆé©çš„å­—é«”
    system = platform.system()

    if system == "Darwin":  # macOS
        font_list = [
            "Arial Unicode MS",  # æœ€å…¼å®¹çš„å­—é«”ï¼Œæ”¯æŒ emoji å’Œä¸­æ–‡
            "Helvetica Neue",
            "Helvetica",
            "Arial",
            "DejaVu Sans",
        ]
    elif system == "Windows":
        font_list = [
            "Arial Unicode MS",  # æœ€å…¼å®¹çš„å­—é«”
            "Segoe UI",
            "Arial",
            "DejaVu Sans",
        ]
    else:  # Linux and others
        font_list = [
            "DejaVu Sans",  # Linux æœ€å¯é çš„å­—é«”
            "Liberation Sans",
            "Arial",
            "Helvetica",
        ]

    # æª¢æŸ¥å­—é«”å¯ç”¨æ€§ä¸¦è¨­ç½®
    available_fonts = []

    for font in font_list:
        try:
            # æ›´åš´æ ¼çš„å­—é«”æª¢æŸ¥
            font_path = fm.findfont(font)
            if font_path and font_path != matplotlib.rcParams["font.sans-serif"][0]:
                available_fonts.append(font)
        except Exception:
            continue

    # å¦‚æœæ²’æœ‰æ‰¾åˆ°åˆé©å­—é«”ï¼Œä½¿ç”¨åŸºæœ¬å­—é«”
    if not available_fonts:
        available_fonts = ["DejaVu Sans", "Arial", "Helvetica"]

    # è¨­ç½®å­—é«”åƒæ•¸
    plt.rcParams["font.sans-serif"] = available_fonts
    plt.rcParams["axes.unicode_minus"] = False
    plt.rcParams["figure.facecolor"] = "white"
    plt.rcParams["axes.facecolor"] = "#f8f9fa"

    # ä½¿ç”¨æ›´å¯é çš„æ–¹æ³•è¨­ç½® unicode_minus
    plt.rc("axes", unicode_minus=False)

    # æ¸…é™¤å­—é«”ç·©å­˜ä»¥ç¢ºä¿æ–°é…ç½®ç”Ÿæ•ˆ
    try:
        # å˜—è©¦æ¸…é™¤å­—é«”ç·©å­˜
        if hasattr(fm.findfont, "cache_clear"):
            fm.findfont.cache_clear()
    except Exception:
        pass

    # è¨­ç½®å…¨å±€è­¦å‘Šéæ¿¾
    warnings.filterwarnings("ignore", category=UserWarning, module="matplotlib")
    warnings.filterwarnings("ignore", category=UserWarning, module="matplotlib.font_manager")
    warnings.filterwarnings("ignore", category=UserWarning, module="matplotlib.backends")
    warnings.filterwarnings("ignore", category=RuntimeWarning, module="matplotlib")

    return True, True


# é…ç½®å­—é«”ä¸¦ç²å–æ”¯æŒç‹€æ…‹
EMOJI_SUPPORTED, CHINESE_SUPPORTED = configure_matplotlib_fonts()

# å°ˆæ¥­é…è‰²æ–¹æ¡ˆ
HOURLY_COLORS = {
    "morning": "#ffbe0b",  # æ—©æ™¨ 6-11
    "noon": "#fb5607",  # ä¸­åˆ 12-17
    "evening": "#8338ec",  # æ™šä¸Š 18-23
    "night": "#3a86ff",  # æ·±å¤œ 0-5
    "primary": "#06d6a0",
    "secondary": "#f77f00",
    "accent": "#fcbf49",
}


class HourlyAnalyzer:
    """æ¯å°æ™‚æ•¸æ“šåˆ†æå™¨"""

    def __init__(self, db: Database):
        self.db = db

    def get_hourly_summary(self, days=7):
        """ç²å–æ¯å°æ™‚æ•¸æ“šæ‘˜è¦"""
        try:
            latest_date = self.db.get_latest_date_from_table("hourly_rankings")
            if not latest_date:
                logger.warning("No hourly data found to analyze.")
                return None

            start_date = latest_date - timedelta(days=days - 1)

            data = self.db.get_hourly_rankings(
                start_date=start_date.strftime("%Y-%m-%d"),
                end_date=latest_date.strftime("%Y-%m-%d"),
            )

            if not data:
                return pd.DataFrame()

            df = pd.DataFrame(data)

            # Perform aggregation in pandas
            summary_df = (
                df.groupby("hour")
                .agg(
                    total_records=("hour", "size"),
                    unique_queries=("query", "nunique"),
                    days_active=("date", "nunique"),
                    total_clicks=("clicks", "sum"),
                    total_impressions=("impressions", "sum"),
                    avg_position=("position", "mean"),
                    avg_ctr=("ctr", "mean"),
                )
                .reset_index()
            )
            return summary_df

        except Exception as e:
            logger.error(f"ç²å–æ¯å°æ™‚æ‘˜è¦éŒ¯èª¤: {e}")
            return None

    def get_daily_hourly_heatmap(self, days=7):
        """ç²å–æ¯æ—¥æ¯å°æ™‚ç†±åŠ›åœ–æ•¸æ“š"""
        try:
            latest_date = self.db.get_latest_date_from_table("hourly_rankings")
            if not latest_date:
                return None

            start_date = latest_date - timedelta(days=days - 1)

            data = self.db.get_hourly_rankings(
                start_date=start_date.strftime("%Y-%m-%d"),
                end_date=latest_date.strftime("%Y-%m-%d"),
            )

            if not data:
                return pd.DataFrame()

            df = pd.DataFrame(data)

            heatmap_df = (
                df.groupby(["date", "hour"])
                .agg(
                    records=("hour", "size"),
                    clicks=("clicks", "sum"),
                    impressions=("impressions", "sum"),
                    avg_position=("position", "mean"),
                )
                .reset_index()
            )
            return heatmap_df

        except Exception as e:
            logger.error(f"ç²å–ç†±åŠ›åœ–æ•¸æ“šéŒ¯èª¤: {e}")
            return None

    def get_peak_hours_analysis(self, days=7):
        """åˆ†æé«˜å³°æ™‚æ®µ"""
        df = self.get_hourly_summary(days)
        if df is None or df.empty:
            return None

        # å®šç¾©æ™‚æ®µ
        df["time_period"] = df["hour"].apply(self._categorize_hour)

        # æŒ‰æ™‚æ®µèšåˆ
        period_stats = (
            df.groupby("time_period")
            .agg(
                {
                    "total_clicks": "sum",
                    "total_impressions": "sum",
                    "unique_queries": "sum",
                    "avg_position": "mean",
                }
            )
            .reset_index()
        )

        return df, period_stats

    def _categorize_hour(self, hour):
        """å°‡å°æ™‚åˆ†é¡ç‚ºæ™‚æ®µ"""
        if 6 <= hour <= 11:
            return "æ—©æ™¨ (6-11)"
        elif 12 <= hour <= 17:
            return "ä¸­åˆ (12-17)"
        elif 18 <= hour <= 23:
            return "æ™šä¸Š (18-23)"
        else:  # 0-5
            return "æ·±å¤œ (0-5)"

    def plot_hourly_trends(self, days=7, save_path=None):
        """ç¹ªè£½æ¯å°æ™‚è¶¨å‹¢åœ–"""
        df = self.get_hourly_summary(days)
        if df is None or df.empty:
            logger.error("ç„¡æ³•ç²å–æ¯å°æ™‚æ•¸æ“š")
            return None

        fig = plt.figure(figsize=(16, 12), constrained_layout=True)
        gs = fig.add_gridspec(3, 2, height_ratios=[2, 2, 1])

        # ä¸»è¦è¶¨å‹¢åœ–
        ax1 = fig.add_subplot(gs[0, :])

        # é›™è»¸ï¼šé»æ“Šé‡å’Œæ›å…‰é‡
        ax1_twin = ax1.twinx()

        # é»æ“Šé‡ç·šæ¢
        ax1.plot(
            df["hour"],
            df["total_clicks"],
            color=HOURLY_COLORS["primary"],
            linewidth=4,
            marker="o",
            markersize=8,
            markerfacecolor="white",
            markeredgewidth=3,
            markeredgecolor=HOURLY_COLORS["primary"],
            label="é»æ“Šé‡",
        )

        # æ›å…‰é‡å€åŸŸåœ–
        ax1_twin.fill_between(
            df["hour"],
            df["total_impressions"],
            color=HOURLY_COLORS["secondary"],
            alpha=0.3,
        )
        ax1_twin.plot(
            df["hour"],
            df["total_impressions"],
            color=HOURLY_COLORS["secondary"],
            linewidth=2,
            linestyle="--",
            label="æ›å…‰é‡",
        )

        # ç¾åŒ–ä¸»åœ–
        ax1.set_title(f"24å°æ™‚æœç´¢è¡¨ç¾è¶¨å‹¢ (è¿‘{days}å¤©)", fontsize=18, fontweight="bold", pad=20)
        ax1.set_xlabel("å°æ™‚", fontsize=12, fontweight="bold")
        ax1.set_ylabel("é»æ“Šé‡", fontsize=12, color=HOURLY_COLORS["primary"], fontweight="bold")
        ax1_twin.set_ylabel(
            "æ›å…‰é‡", fontsize=12, color=HOURLY_COLORS["secondary"], fontweight="bold"
        )

        # è¨­ç½®åˆ»åº¦
        ax1.set_xticks(range(0, 24, 2))
        ax1.grid(True, alpha=0.3)

        # æ·»åŠ åœ–ä¾‹
        lines1, labels1 = ax1.get_legend_handles_labels()
        lines2, labels2 = ax1_twin.get_legend_handles_labels()
        ax1.legend(lines1 + lines2, labels1 + labels2, loc="upper left")

        # å­åœ–1ï¼šæ¯å°æ™‚é—œéµå­—æ•¸é‡
        ax2 = fig.add_subplot(gs[1, 0])
        ax2.bar(
            df["hour"],
            df["unique_queries"],
            color=HOURLY_COLORS["accent"],
            alpha=0.8,
            edgecolor="white",
            linewidth=1,
        )
        ax2.set_title("æ¯å°æ™‚é—œéµå­—æ•¸é‡", fontsize=14, fontweight="bold")
        ax2.set_xlabel("å°æ™‚")
        ax2.set_ylabel("é—œéµå­—æ•¸é‡")
        ax2.set_xticks(range(0, 24, 2))
        ax2.grid(True, alpha=0.3)

        # å­åœ–2ï¼šæ¯å°æ™‚å¹³å‡æ’å
        ax3 = fig.add_subplot(gs[1, 1])
        ax3.plot(
            df["hour"],
            df["avg_position"],
            color="#e74c3c",
            linewidth=3,
            marker="s",
            markersize=6,
        )
        ax3.fill_between(df["hour"], df["avg_position"], color="#e74c3c", alpha=0.3)
        ax3.set_title("æ¯å°æ™‚å¹³å‡æ’å", fontsize=14, fontweight="bold")
        ax3.set_xlabel("å°æ™‚")
        ax3.set_ylabel("å¹³å‡æ’å")
        ax3.set_xticks(range(0, 24, 2))
        ax3.invert_yaxis()
        ax3.grid(True, alpha=0.3)

        # çµ±è¨ˆæ‘˜è¦
        ax4 = fig.add_subplot(gs[2, :])
        ax4.axis("off")

        # è¨ˆç®—çµ±è¨ˆæ•¸æ“š
        peak_hour = df.loc[df["total_clicks"].idxmax()]
        low_hour = df.loc[df["total_clicks"].idxmin()]
        total_clicks = df["total_clicks"].sum()
        total_impressions = df["total_impressions"].sum()

        # ä½¿ç”¨ç´”æ–‡å­—æ ¼å¼ï¼Œé¿å… emoji å­—é«”å•é¡Œ
        stats_text = f"""
        çµ±è¨ˆæ‘˜è¦ (è¿‘{days}å¤©)

        [é«˜å³°] é«˜å³°æ™‚æ®µ: {peak_hour["hour"]}é» ({peak_hour["total_clicks"]:,}æ¬¡é»æ“Š)
        [ä½è°·] ä½è°·æ™‚æ®µ: {low_hour["hour"]}é» ({low_hour["total_clicks"]:,}æ¬¡é»æ“Š)
        [è¶¨å‹¢] é»æ“Šç¸½é‡: {total_clicks:,}
        [æ›å…‰] æ›å…‰ç¸½é‡: {total_impressions:,}
        [é—œéµå­—] é—œéµå­—ç¸½æ•¸: {df["unique_queries"].sum():,}
        """

        ax4.text(
            0.05,
            0.5,
            stats_text,
            transform=ax4.transAxes,
            fontsize=12,
            verticalalignment="center",
            bbox=dict(boxstyle="round,pad=0.5", facecolor="lightgray", alpha=0.8),
        )

        # Using constrained_layout instead of tight_layout for better compatibility

        if save_path:
            if not save_path.endswith((".png", ".jpg", ".jpeg", ".pdf")):
                save_path += ".png"

            save_path_obj = Path(save_path)
            if not save_path_obj.parent.exists():
                save_path_obj.parent.mkdir(parents=True, exist_ok=True)
            plt.savefig(
                save_path_obj,
                dpi=300,
                bbox_inches="tight",
                facecolor="white",
                edgecolor="none",
            )
            logger.info(f"ğŸ“ˆ æ¯å°æ™‚è¶¨å‹¢åœ–å·²ä¿å­˜åˆ°: {save_path}")
            return save_path
        else:
            plt.show()
            return None

    def plot_heatmap(self, days=7, save_path=None):
        """ç¹ªè£½æ¯æ—¥æ¯å°æ™‚ç†±åŠ›åœ–"""
        df = self.get_daily_hourly_heatmap(days)
        if df is None or df.empty:
            logger.error("ç„¡æ³•ç²å–ç†±åŠ›åœ–æ•¸æ“š")
            return None

        # å‰µå»ºé€è¦–è¡¨
        pivot_clicks = df.pivot(index="date", columns="hour", values="clicks").fillna(0)
        pivot_impressions = df.pivot(index="date", columns="hour", values="impressions").fillna(0)

        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(16, 10), constrained_layout=True)

        # é»æ“Šé‡ç†±åŠ›åœ–
        sns.heatmap(
            pivot_clicks,
            annot=True,
            fmt=".0f",
            cmap="YlOrRd",
            ax=ax1,
            cbar_kws={"label": "é»æ“Šé‡"},
        )
        ax1.set_title("æ¯æ—¥æ¯å°æ™‚é»æ“Šé‡åˆ†å¸ƒ", fontsize=16, fontweight="bold", pad=20)
        ax1.set_xlabel("å°æ™‚", fontsize=12)
        ax1.set_ylabel("æ—¥æœŸ", fontsize=12)

        # æ›å…‰é‡ç†±åŠ›åœ–
        sns.heatmap(
            pivot_impressions,
            annot=True,
            fmt=".0f",
            cmap="Blues",
            ax=ax2,
            cbar_kws={"label": "æ›å…‰é‡"},
        )
        ax2.set_title("æ¯æ—¥æ¯å°æ™‚æ›å…‰é‡åˆ†å¸ƒ", fontsize=16, fontweight="bold", pad=20)
        ax2.set_xlabel("å°æ™‚", fontsize=12)
        ax2.set_ylabel("æ—¥æœŸ", fontsize=12)

        # Using constrained_layout instead of tight_layout for better compatibility

        if save_path:
            if not save_path.endswith((".png", ".jpg", ".jpeg", ".pdf")):
                save_path += ".png"

            save_path_obj = Path(save_path)
            if not save_path_obj.parent.exists():
                save_path_obj.parent.mkdir(parents=True, exist_ok=True)
            plt.savefig(
                save_path_obj,
                dpi=300,
                bbox_inches="tight",
                facecolor="white",
                edgecolor="none",
            )
            logger.info(f"ğŸ”¥ ç†±åŠ›åœ–å·²ä¿å­˜åˆ°: {save_path}")
            return save_path
        else:
            plt.show()
            return None

    def plot_peak_analysis(self, days=7, save_path=None):
        """ç¹ªè£½é«˜å³°æ™‚æ®µåˆ†æ"""
        result = self.get_peak_hours_analysis(days)
        if result is None:
            logger.error("ç„¡æ³•ç²å–é«˜å³°åˆ†ææ•¸æ“š")
            return None

        hourly_df, period_df = result
        if hourly_df is None or period_df is None:
            logger.error("ç„¡æ³•ç²å–é«˜å³°åˆ†ææ•¸æ“š")
            return None

        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(
            2, 2, figsize=(16, 12), constrained_layout=True
        )

        # æ™‚æ®µé»æ“Šé‡åˆ†å¸ƒ
        colors = [
            HOURLY_COLORS["night"],
            HOURLY_COLORS["morning"],
            HOURLY_COLORS["noon"],
            HOURLY_COLORS["evening"],
        ]

        wedges, texts, autotexts = ax1.pie(
            period_df["total_clicks"],
            labels=period_df["time_period"],
            colors=colors,
            autopct="%1.1f%%",
            startangle=90,
        )
        ax1.set_title("å„æ™‚æ®µé»æ“Šé‡åˆ†å¸ƒ", fontsize=14, fontweight="bold")

        # æ™‚æ®µæ›å…‰é‡å°æ¯”
        bars = ax2.bar(
            range(len(period_df)),
            period_df["total_impressions"],
            color=colors,
            alpha=0.8,
            edgecolor="white",
            linewidth=2,
        )
        ax2.set_title("å„æ™‚æ®µæ›å…‰é‡å°æ¯”", fontsize=14, fontweight="bold")
        ax2.set_xticks(range(len(period_df)))
        ax2.set_xticklabels(period_df["time_period"], rotation=45)
        ax2.set_ylabel("æ›å…‰é‡")

        # æ·»åŠ æ•¸å€¼æ¨™ç±¤
        for bar in bars:
            height = bar.get_height()
            ax2.annotate(
                f"{int(height):,}",
                xy=(bar.get_x() + bar.get_width() / 2, height),
                xytext=(0, 3),
                textcoords="offset points",
                ha="center",
                va="bottom",
                fontweight="bold",
            )

        # æ¯å°æ™‚é»æ“Šè¶¨å‹¢ï¼ˆå½©è™¹åœ–ï¼‰
        for i, hour in enumerate(hourly_df["hour"]):
            color = (
                colors[0]
                if hour < 6
                else colors[1]
                if hour < 12
                else colors[2]
                if hour < 18
                else colors[3]
            )
            ax3.bar(
                hour,
                hourly_df.iloc[i]["total_clicks"],
                color=color,
                alpha=0.8,
                width=0.8,
            )

        ax3.set_title("24å°æ™‚é»æ“Šé‡åˆ†å¸ƒ", fontsize=14, fontweight="bold")
        ax3.set_xlabel("å°æ™‚")
        ax3.set_ylabel("é»æ“Šé‡")
        ax3.set_xticks(range(0, 24, 2))

        # æ’åè¡¨ç¾
        ax4.plot(
            hourly_df["hour"],
            hourly_df["avg_position"],
            color="#e74c3c",
            linewidth=3,
            marker="o",
            markersize=5,
        )
        ax4.fill_between(hourly_df["hour"], hourly_df["avg_position"], color="#e74c3c", alpha=0.3)
        ax4.set_title("24å°æ™‚å¹³å‡æ’åè®ŠåŒ–", fontsize=14, fontweight="bold")
        ax4.set_xlabel("å°æ™‚")
        ax4.set_ylabel("å¹³å‡æ’å")
        ax4.set_xticks(range(0, 24, 2))
        ax4.invert_yaxis()

        # Using constrained_layout instead of tight_layout for better compatibility

        if save_path:
            if not save_path.endswith((".png", ".jpg", ".jpeg", ".pdf")):
                save_path += ".png"

            save_path_obj = Path(save_path)
            if not save_path_obj.parent.exists():
                save_path_obj.parent.mkdir(parents=True, exist_ok=True)
            plt.savefig(
                save_path_obj,
                dpi=300,
                bbox_inches="tight",
                facecolor="white",
                edgecolor="none",
            )
            logger.info(f"â° é«˜å³°åˆ†æåœ–å·²ä¿å­˜åˆ°: {save_path}")
            return save_path
        else:
            plt.show()
            return None

    def generate_hourly_report(self, days=7, output_path="hourly_report.md"):
        """ç”Ÿæˆæ¯å°æ™‚æ•¸æ“šåˆ†æå ±å‘Š"""
        report_parts = []
        summary_df = self.get_hourly_summary(days)

        report_parts.append(f"# æ¯å°æ™‚æ•¸æ“šåˆ†æå ±å‘Š (æœ€è¿‘ {days} å¤©)")
        report_parts.append(f"å ±å‘Šç”Ÿæˆæ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

        if summary_df is None or summary_df.empty:
            report_parts.append("\n**æ²’æœ‰è¶³å¤ çš„æ•¸æ“šç”Ÿæˆå ±å‘Šã€‚**")
            Path(output_path).write_text("\n".join(report_parts), encoding="utf-8")
            return

        # åŸºæœ¬çµ±è¨ˆ
        total_records = summary_df["total_records"].sum()
        total_clicks = summary_df["total_clicks"].sum()
        total_impressions = summary_df["total_impressions"].sum()

        report_parts.append("\n## ç¸½é«”æ‘˜è¦")
        report_parts.append(f"- ç¸½è¨˜éŒ„æ•¸: {total_records:,}")
        report_parts.append(f"- ç¸½é»æ“Šæ•¸: {total_clicks:,}")
        report_parts.append(f"- ç¸½æ›å…‰æ•¸: {total_impressions:,}")

        # è¡¨æ ¼æ•¸æ“š
        report_parts.append("\n## æ¯å°æ™‚è©³ç´°æ•¸æ“š")
        report_parts.append(summary_df.to_markdown(index=False))

        # é«˜å³°æ™‚æ®µåˆ†æ
        _, period_stats = self.get_peak_hours_analysis(days)
        if period_stats is not None:
            report_parts.append("\n## é«˜å³°æ™‚æ®µåˆ†æ")
            report_parts.append(period_stats.to_markdown(index=False))

        # å¯«å…¥æ–‡ä»¶
        Path(output_path).write_text("\n".join(report_parts), encoding="utf-8")
        logger.info(f"å ±å‘Šå·²ç”Ÿæˆ: {output_path}")

    def analyze_and_display_coverage(
        self, all_sites: bool = False, site_id: Optional[int] = None, output_csv: bool = False
    ):
        """åˆ†æä¸¦é¡¯ç¤ºæ•¸æ“šè¦†è“‹ç‡"""

        from ..utils.rich_console import console

        console.print("[bold cyan]ğŸ” é–‹å§‹åˆ†ææ•¸æ“šè¦†è“‹ç‡...[/bold cyan]")

        sites_to_check = []
        if all_sites:
            sites_to_check = self.db.get_sites(active_only=True)
        elif site_id:
            site = self.db.get_site_by_id(site_id)
            if site:
                sites_to_check.append(site)

        if not sites_to_check:
            console.print("[yellow]âš ï¸ æœªæ‰¾åˆ°è¦åˆ†æçš„ç«™é»ã€‚[/yellow]")
            return

        for site in sites_to_check:
            self._print_coverage_for_site(self.db, site)
            # Future: add data to coverage_results for CSV export

    def _print_coverage_for_site(self, db: Database, site: Dict[str, Any]):
        """ç‚ºå–®å€‹ç«™é»æ‰“å°æ•¸æ“šè¦†è“‹æƒ…æ³ã€‚"""

        from rich.panel import Panel
        from rich.table import Table

        from ..utils.rich_console import console

        console.print(Panel(f"[bold]ç«™é»: {site['name']} (ID: {site['id']})[/bold]", expand=False))

        daily_coverage = db.get_daily_data_coverage(site["id"])
        hourly_coverage = db.get_hourly_data_coverage(site["id"])

        table = Table(title="æ•¸æ“šè¦†è“‹æƒ…æ³")
        table.add_column("æ•¸æ“šé¡å‹", style="cyan")
        table.add_column("ç¸½è¨˜éŒ„æ•¸", style="magenta")
        table.add_column("æœ€æ—©æ—¥æœŸ", style="green")
        table.add_column("æœ€æ™šæ—¥æœŸ", style="green")
        table.add_column("è¦†è“‹ç‡", style="yellow")

        if daily_coverage:
            table.add_row(
                "æ¯æ—¥æ•¸æ“š",
                str(daily_coverage.get("total_records", "N/A")),
                str(daily_coverage.get("first_date", "N/A")),
                str(daily_coverage.get("last_date", "N/A")),
                self._calculate_coverage_percentage(daily_coverage) or "N/A",
            )
        else:
            table.add_row("æ¯æ—¥æ•¸æ“š", "[red]ç„¡[/red]", "N/A", "N/A", "N/A")

        if hourly_coverage:
            table.add_row(
                "æ¯å°æ™‚æ•¸æ“š",
                str(hourly_coverage.get("total_records", "N/A")),
                str(hourly_coverage.get("first_date", "N/A")),
                str(hourly_coverage.get("last_date", "N/A")),
                self._calculate_coverage_percentage(hourly_coverage) or "N/A",
            )
        else:
            table.add_row("æ¯å°æ™‚æ•¸æ“š", "[red]ç„¡[/red]", "N/A", "N/A", "N/A")

        console.print(table)

    def _calculate_coverage_percentage(self, coverage_data: Dict[str, Any]) -> Optional[str]:
        """è¨ˆç®—ä¸¦æ ¼å¼åŒ–æ•¸æ“šè¦†è“‹ç‡ç™¾åˆ†æ¯”"""
        first_date_str = coverage_data.get("first_date")
        last_date_str = coverage_data.get("last_date")
        unique_dates = coverage_data.get("unique_dates", 0)

        if first_date_str and last_date_str and unique_dates > 0:
            try:
                first_date = datetime.strptime(first_date_str, "%Y-%m-%d").date()
                last_date = datetime.strptime(last_date_str, "%Y-%m-%d").date()
                total_days = (last_date - first_date).days + 1
                percentage = (unique_dates / total_days) * 100 if total_days > 0 else 0
                return f"{percentage:.1f}% ({unique_dates} / {total_days} å¤©)"
            except (ValueError, TypeError):
                return None
        return None


def _generate_hourly_trends_plot(
    analyzer: HourlyAnalyzer, days: int = 7, save_path: Optional[str] = None
) -> Optional[str]:
    """ç”Ÿæˆæ¯å°æ™‚è¶¨å‹¢åœ–"""
    try:
        result = analyzer.plot_hourly_trends(days=days, save_path=save_path)
        return result if isinstance(result, str) else None
    except Exception as e:
        logger.error(f"ç”Ÿæˆæ¯å°æ™‚è¶¨å‹¢åœ–å¤±æ•—: {e}")
        return None


def _generate_hourly_heatmap(
    analyzer: HourlyAnalyzer, days: int = 7, save_path: Optional[str] = None
) -> Optional[str]:
    """ç”Ÿæˆæ¯å°æ™‚ç†±åŠ›åœ–"""
    try:
        result = analyzer.plot_heatmap(days=days, save_path=save_path)
        return result if isinstance(result, str) else None
    except Exception as e:
        logger.error(f"ç”Ÿæˆæ¯å°æ™‚ç†±åŠ›åœ–å¤±æ•—: {e}")
        return None


def _generate_peak_analysis_plot(
    analyzer: HourlyAnalyzer, days: int = 7, save_path: Optional[str] = None
) -> Optional[str]:
    """ç”Ÿæˆé«˜å³°åˆ†æåœ–"""
    try:
        result = analyzer.plot_peak_analysis(days=days, save_path=save_path)
        return result if isinstance(result, str) else None
    except Exception as e:
        logger.error(f"ç”Ÿæˆé«˜å³°åˆ†æåœ–å¤±æ•—: {e}")
        return None


def _generate_hourly_report(
    analyzer: HourlyAnalyzer, days: int = 7, save_path: Optional[str] = None
) -> Optional[str]:
    """ç”Ÿæˆæ¯å°æ™‚å ±å‘Š"""
    try:
        # The analyzer method expects output_path, so we pass save_path to it.
        if save_path is None:
            return None
        result = analyzer.generate_hourly_report(days=days, output_path=save_path)
        return result if isinstance(result, str) else None
    except Exception as e:
        logger.error(f"ç”Ÿæˆæ¯å°æ™‚å ±å‘Šå¤±æ•—: {e}")
        return None


# åˆ†æä»»å‹™è¨»å†Šè¡¨ï¼Œæ–¹ä¾¿æ“´å±•
ANALYSIS_REGISTRY = {
    "trends": {
        "function": _generate_hourly_trends_plot,
        "type": "plot",
        "filename": "hourly_trends.png",
    },
    "heatmap": {
        "function": _generate_hourly_heatmap,
        "type": "plot",
        "filename": "hourly_heatmap.png",
    },
    "peaks": {
        "function": _generate_peak_analysis_plot,
        "type": "plot",
        "filename": "peak_analysis.png",
    },
    "report": {
        "function": _generate_hourly_report,
        "type": "report",
        "filename": "hourly_report.md",
    },
}


def _fetch_hourly_data_gemini(
    db: Database, days: int, site_url: Optional[str] = None
) -> pd.DataFrame:
    """ä½¿ç”¨ Database æœå‹™å¾è³‡æ–™åº«ç²å–æ¯å°æ™‚æ•¸æ“šã€‚"""

    site_id = None
    if site_url:
        site = db.get_site_by_domain(site_url)
        if site:
            site_id = site["id"]
        else:
            logger.warning(f"Gemini Analysis: Site not found for URL {site_url}")
            return pd.DataFrame()

    latest_date = db.get_latest_date_from_table("hourly_rankings", site_id=site_id)
    if not latest_date:
        logger.warning("Gemini Analysis: No hourly data found.")
        return pd.DataFrame()

    start_date = latest_date - timedelta(days=days - 1)

    data = db.get_hourly_rankings(
        site_id=site_id,
        start_date=start_date.strftime("%Y-%m-%d"),
        end_date=latest_date.strftime("%Y-%m-%d"),
    )

    if not data:
        return pd.DataFrame()

    return pd.DataFrame(data)


def _generate_hourly_plot_gemini(
    df: pd.DataFrame, output_dir: Path, filename_prefix: str
) -> Optional[Path]:
    """Generates and saves a plot of clicks by hour of the day (Gemini style)."""
    if df.empty:
        return None
    plt.style.use("seaborn-v0_8-whitegrid")
    plt.figure(figsize=(14, 7), constrained_layout=True)
    sns.barplot(
        x="hour",
        y="total_clicks",
        data=df,
        palette="plasma",
        hue="hour",
        dodge=False,
        legend=False,
    )
    plt.title(f"{filename_prefix} - Clicks by Hour of Day (UTC)", fontsize=16, pad=20)
    plt.xlabel("Hour of Day", fontsize=12)
    plt.ylabel("Total Clicks", fontsize=12)
    plt.xticks(range(0, 24))
    # Using constrained_layout instead of tight_layout for better compatibility
    output_dir.mkdir(parents=True, exist_ok=True)
    plot_path = output_dir / f"{filename_prefix}_Hourly_Trends.png"
    plt.savefig(plot_path)
    plt.close()
    return plot_path


def run_hourly_analysis(
    analyzer: HourlyAnalyzer,
    analysis_type: str = "trends",
    days: int = 7,
    output_path: Optional[str] = None,
    include_plots: bool = True,
    plot_save_dir: Optional[str] = None,
) -> Dict[str, Any]:
    """
    åŸ·è¡Œæ¯å°æ™‚æ•¸æ“šåˆ†æçš„æ ¸å¿ƒå‡½æ•¸ã€‚
    :param analyzer: å·²ç¶“åˆå§‹åŒ–çš„ HourlyAnalyzer å¯¦ä¾‹ã€‚
    :param analysis_type: è¦åŸ·è¡Œçš„åˆ†æé¡å‹ ('trends', 'heatmap', 'peak', 'report', 'coverage')ã€‚
    :param days: åˆ†ææ¶µè“‹çš„å¤©æ•¸ã€‚
    :param output_path: å ±å‘Šæˆ–CSVçš„è¼¸å‡ºè·¯å¾‘ã€‚
    :param include_plots: æ˜¯å¦ç”Ÿæˆåœ–è¡¨ã€‚
    :param plot_save_dir: åœ–è¡¨ä¿å­˜ç›®éŒ„ã€‚
    :return: åˆ†æçµæœå­—å…¸ã€‚
    """
    result: Dict[str, Any] = {"status": "success", "files": [], "errors": []}

    logger.info(f"åŸ·è¡Œåˆ†æé¡å‹: {analysis_type}, æœ€è¿‘ {days} å¤©")

    if analysis_type == "coverage":
        analyzer.analyze_and_display_coverage(all_sites=True)
        return result

    # æª¢æŸ¥æ•¸æ“š
    summary_df = analyzer.get_hourly_summary(days=days)
    if summary_df is None or summary_df.empty:
        error_msg = "æ²’æœ‰è¶³å¤ çš„æ¯å°æ™‚æ•¸æ“šé€²è¡Œåˆ†æã€‚"
        logger.warning(error_msg)
        result["status"] = "failed"
        result["errors"].append(error_msg)
        return result

    if include_plots:
        save_dir = Path(plot_save_dir or config.settings.paths.report_dir)
        save_dir.mkdir(exist_ok=True)

        # çµ±ä¸€æ–‡ä»¶åå‰ç¶´
        filename_prefix = f"hourly_{datetime.now().strftime('%Y%m%d')}"

        plot_functions: Dict[str, Callable] = {
            "trends": _generate_hourly_trends_plot,
            "heatmap": _generate_hourly_heatmap,
            "peak": _generate_peak_analysis_plot,
        }

        if analysis_type in plot_functions:
            plot_path = plot_functions[analysis_type](
                analyzer, days, str(save_dir / f"{filename_prefix}_{analysis_type}.png")
            )
            if plot_path:
                result["files"].append(plot_path)
        elif analysis_type == "report":
            # å ±å‘Šä¹Ÿå¯èƒ½åŒ…å«åœ–è¡¨
            trends_path = _generate_hourly_trends_plot(
                analyzer, days, str(save_dir / f"{filename_prefix}_trends.png")
            )
            heatmap_path = _generate_hourly_heatmap(
                analyzer, days, str(save_dir / f"{filename_prefix}_heatmap.png")
            )
            if trends_path:
                result["files"].append(trends_path)
            if heatmap_path:
                result["files"].append(heatmap_path)

    if analysis_type == "report":
        report_path = output_path or str(config.settings.paths.report_dir / "hourly_report.md")
        _generate_hourly_report(analyzer, days, report_path)
        result["files"].append(report_path)

    logger.info("åˆ†æå®Œæˆã€‚")
    return result


def run_hourly_analysis_gemini(db: Database, site_url: Optional[str] = None, days: int = 30):
    """
    åŸ·è¡Œä¸€å€‹ç°¡åŒ–çš„ã€ç”± Gemini å•Ÿç™¼çš„æ¯å°æ™‚æ•¸æ“šåˆ†æã€‚
    :param db: Database æœå‹™å¯¦ä¾‹ã€‚
    :param site_url: è¦åˆ†æçš„å–®å€‹ç«™é» URL (å¯é¸)ã€‚
    :param days: åˆ†æå¤©æ•¸ã€‚
    """

    from ..utils.rich_console import console

    console.print(
        f"[bold blue]ğŸš€ Starting Gemini Hourly Analysis for "
        f"{site_url or 'all sites'}...[/bold blue]"
    )

    # 1. Fetch data using the refactored function
    df = _fetch_hourly_data_gemini(db, days, site_url)

    if df.empty:
        console.print("[yellow]No data to analyze. Exiting.[/yellow]")
        return

    # 2. Generate Plot
    output_dir = config.settings.paths.report_dir
    output_dir.mkdir(exist_ok=True)
    filename_prefix = f"gemini_hourly_{site_url.replace('.', '_') if site_url else 'all'}"
    plot_path = _generate_hourly_plot_gemini(df, output_dir, filename_prefix)

    if plot_path:
        console.print(f"[green]âœ” Plot generated successfully at: {plot_path}[/green]")
    else:
        console.print("[red]âŒ Failed to generate plot.[/red]")

    # 3. Print summary
    console.print("\n[bold]Data Summary:[/bold]")
    console.print(df.head())


def main():
    """CLI å…¥å£é»"""
    parser = argparse.ArgumentParser(description="GSC æ¯å°æ™‚æ•¸æ“šåˆ†æå·¥å…·")
    parser.add_argument(
        "analysis_type",
        nargs="?",
        default="trends",
        choices=["trends", "heatmap", "peak", "report", "coverage", "gemini"],
        help="è¦åŸ·è¡Œçš„åˆ†æé¡å‹ (é è¨­: trends)",
    )
    parser.add_argument("--days", type=int, default=7, help="åˆ†ææœ€è¿‘ N å¤©çš„æ•¸æ“š (é è¨­: 7)")
    parser.add_argument("--output", type=str, help="å ±å‘Šæˆ–åœ–è¡¨çš„è¼¸å‡ºè·¯å¾‘")
    parser.add_argument("--site-url", type=str, help="é‡å°ç‰¹å®šç«™é»URLé‹è¡Œåˆ†æ (ä¸»è¦ç”¨æ–¼ gemini)")
    args = parser.parse_args()

    try:
        from ..containers import Container

        container = Container()
        container.wire(modules=[__name__])

        # For gemini analysis, we pass the db service directly
        if args.analysis_type == "gemini":
            db_service = container.database()
            run_hourly_analysis_gemini(db=db_service, site_url=args.site_url, days=args.days)
            return

        analyzer = container.hourly_performance_analyzer()

        result = run_hourly_analysis(
            analyzer=analyzer,
            analysis_type=args.analysis_type,
            days=args.days,
            output_path=args.output,
        )

        if result["status"] == "success":
            print("\n[bold green]âœ… åˆ†ææˆåŠŸå®Œæˆï¼[/bold green]")
            if result.get("files"):
                print("ç”Ÿæˆæ–‡ä»¶:")
                for f in result["files"]:
                    print(f"- {f}")
        else:
            print("\n[bold red]âŒ åˆ†æéç¨‹ä¸­å‡ºç¾éŒ¯èª¤:[/bold red]")
            if result.get("errors"):
                for err in result["errors"]:
                    print(f"- {err}")

    except Exception as e:
        logger.error(f"åˆ†æéç¨‹ä¸­ç™¼ç”Ÿæœªé æœŸéŒ¯èª¤: {e}", exc_info=True)


if __name__ == "__main__":
    main()
